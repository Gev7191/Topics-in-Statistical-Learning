---
title: "TSL Project"
author: "L. Insolia, J. Kim and G. Yeghikyan"
date: "February 13, 2018"
output: 
  html_notebook:
    toc: yes
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    highlight: tango
    keep_tex: yes
    number_sections: yes
    # theme: united
  # pdf document:
editor_options: 
  chunk_output_type: inline 
---


# General info #

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

We analyze a dataset published on [Kaggle](https://www.kaggle.com/etiennelq/french-employment-by-town).
It refers to french employment, salaries, population per town. 
The aim is to evaluate equality/inequalities in France, and geographical distribution of business according to their size.

Such data are collected by the INSEE.
Information regarding the number of firms in every french town, categorized by size
can be found [here](https://www.insee.fr/fr/metadonnees/definition/c1135). 
Information about salaries around french town per job categories, age and sex (expressed in average net amount per hour in euro) can be found [here](https://www.insee.fr/fr/statistiques/2522515).
Demographic information in France per town, age, sex and living mode
can be found [here](https://www.insee.fr/fr/statistiques/2863607).



## Aim of the study ##
This project aims to explore existing patterns among French towns.

In particular, we are interested in:

* evaluating possible ineqialities: per towns/region, sex, age, etc.;
* predicting the ... using a regression model;
* reduce the dimensionality of ... performing a PCA;
* explore different algorithms to cluster male/females using ...



# General pre-processing phase #

Choose the working directory according to the user path: [NEEDED?]
```{r}
# Jisu
# setwd("/Users/jisukim/Documents/TSL_INSEE data")
# Luca
setwd("D:/Docs_D/PhD SNS/Classes/Topics in Statistical Learning/Project/git_TSL")
# Gevorg
# setwd("C:/Users/Gevorg/Desktop/TSL")
```

Import data:
```{r warning=FALSE}
setwd("./data")
firms       <- read.csv("base_etablissement_par_tranche_effectif.csv", encoding = "UTF-8")
geo         <- read.csv("name_geographic_information.csv", encoding = "UTF-8")
salary      <- read.csv("net_salary_per_town_categories.csv", encoding = "UTF-8")
population  <- read.csv("population.csv", encoding = "UTF-8")
```

Check variable names:
```{r}
names(firms) 
names(population)
names(salary)
names(geo)
```

To better understand the data we assign meaningful names and drop some variables which are not needed (at the moment):
```{r}
names(firms)[2:ncol(firms)] <-
  c("town", 
    "regNum",
    "deptNum",
    "total",
    "null",
    "firmsEmpl_1_5",
    "firmsEmpl_6_9",
    "firmsEmpl_10_19",
    "firmsEmpl_20_49",
    "firmsEmpl_50_99",
    "firmsEmpl_100_199",
    "firmsEmpl_200_499",
    "firmsEmpl_500plus")

names(salary)[2:ncol(salary)] <-
  c("town",
    "sal_general",    
    "sal_executive",
    "sal_midManager",
    "sal_employee",
    "sal_worker",
    "sal_Females",
    "sal_F_executive",
    "sal_F_midManager",
    "sal_F_employee",
    "sal_F_worker",
    "sal_Males",
    "sal_M_executive",
    "sal_M_midManager",
    "sal_M_employee",
    "sal_M_worker",
    "sal_18_25",
    "sal_26_50",
    "sal_51plus",
    "sal_F_18_25",
    "sal_F_26_50",
    "sal_F_51plus",
    "sal_M_18_25",
    "sal_M_26_50",
    "sal_M_51plus")

names(population)[5:7] <-
  c("ageCateg5",
    "sex",
    "peopleCategNum")

# Drop unnecessary columns (code/num and name represents same thing)
geo <- subset(geo, select = -c(EU_circo, code_région, numéro_département, préfecture, numéro_circonscription, éloignement))
# change names 
names(geo)[1:6] = 
  c("region", 
    "region_capital", 
    "department", 
    "town_name", 
    "postal_code", 
    "CODGEO")
```

According to the information provided, the CODGEO variable (in firms, salary and population) and code_insee (in geo) have to be merged.
However, for different reasons already identified by a kaggle user on [his kernel](https://www.kaggle.com/anqitu/insights-on-business-demographic-inequality) they do not.
To do so:
```{r}
firms$CODGEO <- sub("A", "0", firms$CODGEO)
firms$CODGEO <- sub("B", "0", firms$CODGEO)
salary$CODGEO <- sub("A", "0", salary$CODGEO)
salary$CODGEO <- sub("B", "0", salary$CODGEO)
population$CODGEO <- sub("A", "0", population$CODGEO)
population$CODGEO <- sub("B", "0", population$CODGEO)
```



# Analyze firms data #

## Pre-processing ##
```{r}

# preliminary checks
dim(firms)
names(firms)
head(firms)
str(firms)
summary(firms)

# converting CODGEO format
firms$CODGEO <- as.numeric(firms$CODGEO)

# Check for duplicated data
sum(duplicated.data.frame(firms))

# Categorize firms' size according to EU standard, but slightly different for medium and large firms (medium firms have <200 instead of <250 employees)
# http://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Enterprise_size
firms$micro   <- firms$firmsEmpl_1_5 + firms$firmsEmpl_6_9
firms$small   <- firms$firmsEmpl_10_19 + firms$firmsEmpl_20_49
firms$medium  <- firms$firmsEmpl_50_99 + firms$firmsEmpl_100_199
firms$large   <- firms$firmsEmpl_200_499 + firms$firmsEmpl_500plus

# Drop unnecessary (at the moment) columns 
firms <- subset(firms, select = c(CODGEO, town, total, micro, small, medium, large, null))

# check
head(firms)
summary(firms)

```

## EDA ##

```{r}
# there is an obs with more than 316K null data: we check if it is plausible
# get the highest 20 null values
str_firms <- sort(firms$null, decreasing = T)[1:20]
# get their indexes
str_firms_ind <- match(str_firms, firms$null)
# get the corresponding city
firms$town[str_firms_ind]
# hence, it seems reasonable..

# check the ratio of null for each town
summary(firms$null/firms$total)
# a lot of information is missing
# should we remove these data?
hist(firms$null/firms$total)

# evaluate the distribution of all the sizes 
# (log vs. ratio wrt total?)
hist(log(firms$total))
hist(log(firms$null))
hist(log(firms$micro))
hist(firms$micro/firms$total)
hist(log(firms$small))
hist(firms$small/firms$total)
hist(log(firms$medium))
hist(firms$medium/firms$total)
hist(log(firms$large))
hist(firms$large/firms$total)
```

## What we have learned ##

* More micro firms than small ones
* ... 

## How to use these data ##

We plan to use these for the following tasks:

* predict the salaries using such information as proxy for the competition in the job market;
* predict the total number of firms, using salary data;
* geo-spatial plot for firms' size 
* ... 


# Analyze geographical data #

## Pre-processing ##
```{r}

# preliminary checks
dim(geo)
names(geo)
head(geo)
str(geo)
summary(geo)

# spot "," instead of "." in longitude
newLong       <- as.character(geo$longitude)     # copy the vector
sum(grep(",", newLong))                   # total commas
ind_long_err  <- grep(",", newLong)       # indexing them
newLong       <- gsub(",", ".", newLong)  # substituting them with dots
# spot NA
indNA_Long    <- is.na(as.numeric((newLong)))
# verify that they were actually missing
geo$longitude[indNA_Long]
# overwrite the longitude variable with the new one
geo$longitude <- as.numeric(newLong)

# compare numbers of NA in latitude and longitude 
sum(is.na(geo$latitude)) - sum(is.na(geo$longitude))
# check if they match or not
sum(!is.na(geo$latitude[indNA_Long]))
# 64 obs are missing in longitude but not in latitude, hence 88 vice versa

# Check for duplicated data (e.g., cities with different postal codes, that we dropped):
  # es. to try on the initial dataset
  # sum(geo$nom_commune == "Paris")
  # ind_duplic <- geo$nom_commune == "Paris"
  # geo[ind_duplic,]
sum(duplicated.data.frame(geo)) 
geo <- unique(geo, by = "CODGEO")

# check again
head(geo)
summary(geo)

```


Assign lat and long values for NAs units:
```{r}
require(ggmap)

# index of NAs
indNA_coord = is.na(geo$latitude) | is.na(geo$longitude)
# corresponding obs
NA_coord = geo[indNA_coord,]

# google key for API
# https://developers.google.com/maps/documentation/geocoding/get-api-key
# register_google(key = key)
# key = "AIzaSyBqoOaevlfn5kTtQTOc1muK4lREAaUjPy8"
# install.packages("googleway")
# require(googleway)

# initialize variables
city_search = 0
res = as.data.frame(matrix(c(0, 0, 0), 1, 3))
names(res) = c("lon", "lat", "address")

# retrieve lat and long
# my_iter = floor(sum(indNA_coord)/3)
for (i in 1:2){

  # city searched
  city_search[i] = paste(c(as.character(NA_coord$town_name[i]), as.character(NA_coord$postal_code[i]), as.character(NA_coord$department[i]), "France"), sep=" ", collapse = ", ")
  
  # solution
  res[i,] = geocode(city_search[i], output = "latlona", source = c("google", "dsk"), messaging = FALSE)

  # retrieve still missing data, because of existing problems with API (up to 15 trials)
  j = 0
  while (any(is.na(res[i,])) & j < 15){
    res[i,] = geocode(city_search[i], output = "latlona", source = c("google", "dsk"), messaging = FALSE)
    j = j + 1
  }
  
}

# check the solution
sol = cbind(searched = city_search, res)
# save it as a csv file to save time
write.csv(sol, file = "geo_NAcoordinates", row.names=FALSE)
# read it
# sol = ?read.csv("geo_NAcoordinates", header = TRUE)

# get only long and lat and assign to original NA 
# geo$latitude[indNA_coord] = sol[,3]
# geo$longitude[indNA_coord] = sol[,2]

```

## EDA ##

```{r}
# install.packages("ggplot2")
# install.packages("ggmap")
require(ggplot2)
require(ggmap)

# plot france
fra_center = as.numeric(geocode("France"))
FraMap = ggmap(get_googlemap(center=fra_center, scale=2, zoom=6), extent="normal")
FraMap

# plot available cities
geo_pos = as.data.frame(cbind(lon = geo$longitude, lat = geo$latitude))
geo_pos = geo_pos[complete.cases(geo_pos),]
FraMap +
  geom_point(aes(x=lon, y=lat), data=geo_pos, col="orange", alpha=0.4) 


```

PCA on firms data:
```{r}
firms_clean <- firms[firms$micro < 20000 & firms$large < 200,]
myPr <- prcomp(firms_clean[, 4:8], scale = TRUE)
#plot(scale(firms_clean$micro), scale(firms_clean$large))
#mean(firms_clean$micro)
#mean(firms_clean$large)
myPr
summary(myPr)
plot(myPr, type = "l")
biplot(myPr, scale = 0)
#extract PC scores...
str(myPr)
#myPr$x #checking principal component scores
firms2 <- cbind(firms_clean, myPr$x[, 1:2])
head(firms2)
#plot with ggplot...
require(ggplot2)
ggplot(firms2, aes(PC1, PC2)) + 
  stat_ellipse(geom = "polygon", col = "black", alpha = 0.5) + 
  geom_point(shape = 21, col = "black")
# correlations between variables and PCs...
cor(firms_clean[, 4:8], firms2[,9:10])
```

## What we have learned ##

Solved: 

* Why latitude is missing and not longitude?
* There are some duplications.

To do:
* ...

## How to use these data ##

* ...



# Analyze salary data #

## Pre-processing ##

```{r}
# preliminary checks
dim(salary)
names(salary)
head(salary)
str(salary)
summary(salary)

# Drop unnecessary columns (town name repeats in other table, is it surely possible to merge them?)
names(salary)
# salary <- subset(salary, select = -c(town))

# Convert CODGEO to numeric
salary$CODGEO <- as.numeric(as.character(salary$CODGEO))

# Check for duplicated data
sum(duplicated.data.frame(salary))



```


## EDA ##

Univariate analysis comparing genders:  [to be done on the same plot!]
```{r}
# General:
require(ggplot2)
#  number of units
n_sex <- length(salary$sal_Females)
# vector representing males and females
Label <- c(rep("M", n_sex*5), rep("F", n_sex*5))
# vector representing the variable considered
Variable <- c(rep("General", n_sex), 
             rep("Executive", n_sex),
             rep("MidManager", n_sex),
             rep("Employee", n_sex),
             rep("Worker",n_sex),
             rep("General", n_sex), 
             rep("Executive", n_sex),
             rep("MidManager", n_sex),
             rep("Employee", n_sex),
             rep("Worker",n_sex))
# merge these data
sal_sex = cbind.data.frame(Label = Label, 
             value = c(salary$sal_Males, salary$sal_M_executive, salary$sal_M_midManager, salary$sal_M_employee, salary$sal_M_worker,
                       salary$sal_Females, salary$sal_F_executive, salary$sal_F_midManager, salary$sal_F_employee, salary$sal_F_worker),
             Variable = Variable)
p <- ggplot(data = sal_sex, aes(x=Label, y=value)) 
p <- p + geom_boxplot(aes(fill = Label))
# if you want color for points replace group with colour=Label
p <- p + geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75))
p <- p + facet_wrap( ~ Variable, scales="free")
p <- p + xlab("x-axis") + ylab("y-axis") + ggtitle("Gender comparison")
# p <- p + guides(fill=guide_legend(title="Legend"))
p 
```



Bivariate relations:
```{r}
pairs(salary[c(3:8, 13, 18:20)])
```

We fit a regression model to predict the salaries of people in age 26-50 using as regressor the ones for 51+ years:

```{r}
plot(salary$sal_26_50 ~ salary$sal_51plus)
fit_LM = lm(salary$sal_26_50 ~ salary$sal_51plus)
summary(fit_LM)
plot(fit_LM)
```

Now we try to model salaries for younger people, which seems difficult to predict:
```{r}
fit_LM_2 = lm(salary$sal_M_18_25 ~ salary$sal_26_50 + salary$sal_51plus + salary$sal_general + salary$sal_executive + 
                salary$sal_midManager + salary$sal_employee + salary$sal_worker)
summary(fit_LM_2)
```

PCA for salary:
```{r}
myPr <- prcomp(salary[, 3:26], scale = TRUE)
myPr
summary(myPr)
plot(myPr, type = "l")
biplot(myPr, scale = 0, cex = 0.5)
str(myPr)
#myPr$x #checking principal component scores
salary2 <- cbind(salary, myPr$x[, 1:2])
head(salary2)
#plot with ggplot...
#require(ggplot2)
ggplot(salary2, aes(PC1, PC2)) + 
  stat_ellipse(geom = "polygon", col = "black", alpha = 0.5) + 
  geom_point(shape = 21, col = "black")
# correlations between variables and PCs...
cor(salary[, 3:26], salary2[,27:28])
```


## What we have learned ##

* ... 

## How to use these data ##

* ...



# Analyze population data #

## Pre-processing ##


```{r}
# preliminary checks
names(population)
summary(population)

# Drop unnecessary columns (NIVGEO is the same for all)
population <- subset(population, select = -c(NIVGEO, LIBGEO))

# converting CODGEO to numeric
population$CODGEO <- as.numeric(population$CODGEO)

# Refactor sex and MOCO
population$MOCO <- factor(population$MOCO, levels = c(11,12,21,22,23,31,32),
            labels = c("children_living_with_two_parents", "children living with one parent",
                       "adults_living_in_couple_without_child", "adults_living_in_couple_with_children",
                       "adults_living_alone_with_children","persons not from family living in the home",
                       "persons_living_alone"))
population$sex <- factor(population$sex, levels = c(1,2), labels = c("Male", "Female"))

# Take out rows with NB (number of people in this category) equal to 0
population <- population[population$peopleCategNum != 0,]

head(population)
summary(population)



```

## EDA ##


# Merging the datasets #


# Analysis #

## PCA ##

## Regression ##

## Clustering ##


```{r}
summary(firms)
summary(geo)
summary(population)
summary(salary)
```


