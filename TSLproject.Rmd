---
title: "TSL Project"
author: "L. Insolia, J. Kim and G. Yeghikyan"    
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output:
  html_notebook:
    # df_print: paged
    toc: yes
    toc_depth: '3' # up to three depths of headings (specified by #, ## and ###)
    highlight: tango
    keep_tex: yes
    number_sections: yes
    # theme: united
  # pdf document:
  html_document:
    theme: united
    highlight: tango    
    toc: yes
    toc_depth: '3' 
  pdf_document:
    toc: yes
    toc_depth: '3'
    keep_tex: true
    latex_engine: pdflatex
editor_options:
  # toc: yes
  # toc_depth: 3
  chunk_output_type: inline
---


# General information #
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

We analyze a dataset published on [Kaggle](https://www.kaggle.com/etiennelq/french-employment-by-town).
It refers to french employment, salaries, population per town. 
The aim is to evaluate equality/inequalities in France, and geographical distribution of business according to their size.

Such data are collected by the INSEE.
Information regarding the number of firms in every french town, categorized by size
can be found [here](https://www.insee.fr/fr/metadonnees/definition/c1135). 
Information about salaries around french town per job categories, age and sex (expressed in average net amount per hour in euro) can be found [here](https://www.insee.fr/fr/statistiques/2522515).
Demographic information in France per town, age, sex and living mode
can be found [here](https://www.insee.fr/fr/statistiques/2863607).

Additional info about Population Data can be found [here](https://www.insee.fr/fr/statistiques/2863607#dictionnaire), 
it allows to add cat?gorie socioprofessionnelle.




## Aim of the study ##
This project aims to explore existing patterns among French towns.

In particular, we are interested in:

* evaluating possible inequalities: per towns/region, sex, age, etc.;
* predicting the ... using a regression model;
* reduce the dimensionality of ... performing a PCA;
* explore different algorithms to cluster male/females using ...



# General pre-processing phase #

Import data:
```{r warning=FALSE}
# options(encoding = "UTF-8")  # for Mac [PROBABLY, to check]
# options(encoding = "ISO-8859-1")  # for Windows [PROBABLY NOT WORKING]
setwd("./data")
firms       <- read.csv("base_etablissement_par_tranche_effectif.csv", encoding = "UTF-8")
geo         <- read.csv("name_geographic_information.csv", encoding = "UTF-8")
salary      <- read.csv("net_salary_per_town_categories.csv", encoding = "UTF-8")
population  <- read.csv("population.csv", encoding = "UTF-8")
```

Check variable names:
```{r}
names(firms) 
names(population)
names(salary)
names(geo)
```

To better understand the data we assign meaningful names and drop some variables which are not needed (at the moment):
```{r} 
names(firms)[2:ncol(firms)] <-
  c("town", 
    "regNum",
    "deptNum",
    "total",
    "null",
    "firmsEmpl_1_5",
    "firmsEmpl_6_9",
    "firmsEmpl_10_19",
    "firmsEmpl_20_49",
    "firmsEmpl_50_99",
    "firmsEmpl_100_199",
    "firmsEmpl_200_499",
    "firmsEmpl_500plus")

names(salary)[2:ncol(salary)] <-
  c("town",
    "sal_general",    
    "sal_executive",
    "sal_midManager",
    "sal_employee",
    "sal_worker",
    "sal_Females",
    "sal_F_executive",
    "sal_F_midManager",
    "sal_F_employee",
    "sal_F_worker",
    "sal_Males",
    "sal_M_executive",
    "sal_M_midManager",
    "sal_M_employee",
    "sal_M_worker",
    "sal_18_25",
    "sal_26_50",
    "sal_51plus",
    "sal_F_18_25",
    "sal_F_26_50",
    "sal_F_51plus",
    "sal_M_18_25",
    "sal_M_26_50",
    "sal_M_51plus")

names(population)[5:7] <-
  c("ageCateg5",
    "sex",
    "peopleCategNum")

# Drop unnecessary columns (code/num and name represents same thing)
geo <- subset(geo, select = -c(EU_circo, code_région, numéro_département, préfecture, numéro_circonscription, éloignement))# change names 
names(geo)[1:6] = 
  c("region", 
    "region_capital", 
    "department", 
    "town_name", 
    "postal_code", 
    "CODGEO")
```

Check variable names:
```{r}
names(firms) 
names(population)
names(salary)
names(geo)
```


[[MOVE LATER]]
According to the information provided, the CODGEO variable (in firms, salary and population) and code_insee (in geo) have to be merged.
However, for different reasons already identified by a kaggle user on [his kernel](https://www.kaggle.com/anqitu/insights-on-business-demographic-inequality) they do not.
To do so:
```{r}
firms$CODGEO <- sub("A", "0", firms$CODGEO)
firms$CODGEO <- sub("B", "0", firms$CODGEO)
salary$CODGEO <- sub("A", "0", salary$CODGEO)
salary$CODGEO <- sub("B", "0", salary$CODGEO)
population$CODGEO <- sub("A", "0", population$CODGEO)
population$CODGEO <- sub("B", "0", population$CODGEO)
```



# Analyze firms data #

## Pre-processing ##
```{r}

# preliminary checks
dim(firms)
names(firms)
head(firms)
str(firms)
summary(firms)

# converting CODGEO format
firms$CODGEO <- as.numeric(firms$CODGEO)

# Check for duplicated data
sum(duplicated.data.frame(firms))

# Categorize firms' size according to EU standard, but slightly different for medium and large firms (medium firms have <200 instead of <250 employees)
# http://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Enterprise_size
firms$micro   <- firms$firmsEmpl_1_5 + firms$firmsEmpl_6_9
firms$small   <- firms$firmsEmpl_10_19 + firms$firmsEmpl_20_49
firms$medium  <- firms$firmsEmpl_50_99 + firms$firmsEmpl_100_199
firms$large   <- firms$firmsEmpl_200_499 + firms$firmsEmpl_500plus

# Drop unnecessary (at the moment) columns 
firms <- subset(firms, select = c(CODGEO, town, total, micro, small, medium, large, null))

# check
head(firms)
summary(firms)
str(firms)
# deptNum has to be factor?
```

## EDA ##
  
```{r}
# there is an obs with more than 316K null data: we check if it is plausible
# get the highest 20 null values
str_firms <- sort(firms$null, decreasing = T)[1:20]
# get their indexes
str_firms_ind <- match(str_firms, firms$null)
# get the corresponding city
firms$town[str_firms_ind]
# hence, it seems reasonable..

# check the ratio of null for each town
summary(firms$null/firms$total)
# a lot of information is missing
# should we remove these data?
hist(firms$null/firms$total)

# evaluate the distribution of all the sizes 
# (log vs. ratio wrt total?)
hist(log(firms$total))
hist(log(firms$null))
hist(log(firms$micro))
hist(firms$micro/firms$total)
hist(log(firms$small))
hist(firms$small/firms$total)
hist(log(firms$medium))
hist(firms$medium/firms$total)
hist(log(firms$large))
hist(firms$large/firms$total)

# keep only logs?

```

## PCA ##   

PCA on firms data:
```{r}
firms_clean <- firms[firms$micro < 20000 & firms$large < 200,]
myPr <- prcomp(firms_clean[, 4:8], scale = TRUE)
#plot(scale(firms_clean$micro), scale(firms_clean$large))
#mean(firms_clean$micro)
#mean(firms_clean$large)
myPr
summary(myPr)
plot(myPr, type = "l")
biplot(myPr, scale = 0)
#extract PC scores...
str(myPr)
#myPr$x #checking principal component scores
firms2 <- cbind(firms_clean, myPr$x[, 1:2])
head(firms2)
#plot with ggplot...
require(ggplot2)
ggplot(firms2, aes(PC1, PC2)) + 
  stat_ellipse(geom = "polygon", col = "black", alpha = 0.5) + 
  geom_point(shape = 21, col = "black")
# correlations between variables and PCs...
cor(firms_clean[, 4:8], firms2[,9:10])
```

## Cluster Analysis ##

```{r}
set.seed(1000)
firms_sampled <- firms[sample(nrow(firms), 1000), ] # subsampling
head(firms_sampled)

firms_scaled <- scale(firms_sampled[, 3:8]) #scaling the data
head(firms_scaled)

firms_truncated <- firms_sampled[, 4:8]
head(firms_truncated)
plot(firms_sampled)

# K-means clustering...

fitK_scaled <- kmeans(firms_scaled, 4) 
fitK_scaled

fitK <- kmeans(firms_truncated, 5)
fitK
str(fitK)
plot(firms_sampled, col = fitK$cluster) #plotting data colored according to cluster membership

#choosing K---
k <- list()
for(i in 1:10){
  k[[i]] <- kmeans(firms_truncated, i)
}
k

betweenss_totalss <- list()
for(i in 1:10){
  betweenss_totalss[[i]] <- k[[i]]$betweenss/k[[i]]$totss
}
plot(1:10, betweenss_totalss, type ="b",
     ylab = "Between SS / Total SS", xlab = "Clusters (k)") #calculating and plotting between SS to total SS ratio against number of clusters

for(i in 1:5) {
  plot(firms, col = k[[i]]$cluster) #plotting data based on membership to clusters for k = 1 to 5 clusters
}

#Hierarchical clustering---

d <- dist(firms_truncated)
fitH <- hclust(d, "ward.D2")
plot(fitH)
rect.hclust(fitH, k = 5, border = "red") # visualising dendrogam cut at k =5
clusters <- cutree(fitH, 5)  # vector with cluster membership for each observation
clusters
plot(firms_sampled, col = clusters) # as we can see, it performs quite similar to the K-means 

#Model-based clustering

library(mclust)
fitM <- Mclust(firms_truncated)
fitM
plot(fitM)

```


## What we have learned ##

* More micro firms than small ones
* ... 

## How to use these data ##

We plan to use these for the following tasks:

* predict the salaries using such information as proxy for the competition in the job market;
* predict the total number of firms, using salary data;
* geo-spatial plot for firms' size 
* ... 


# Analyze geographical data #

## Pre-processing ##
```{r}

# preliminary checks
dim(geo)
names(geo)
head(geo)
str(geo)
summary(geo)

# spot "," instead of "." in longitude
newLong       <- as.character(geo$longitude)    # copy the vector
sum(grep(",", newLong))                         # total commas
ind_long_err  <- grep(",", newLong)             # indexing them
newLong       <- gsub(",", ".", newLong)        # substituting them with dots
indNA_Long    <- is.na(as.numeric((newLong)))   # spot NA
geo$longitude[indNA_Long]                       # verify that they were actually missing
geo$longitude <- as.numeric(newLong)            # overwrite the longitude variable with the new one

# Check for duplicated data (e.g., cities with different postal codes, that we dropped):
  # es. to verify it:  try on the initial dataset
  # sum(geo$nom_commune == "Paris")
  # ind_duplic <- geo$nom_commune == "Paris"
  # geo[ind_duplic,]
sum(duplicated.data.frame(geo)) 
# retaing unique postal cities
geo <- unique(geo, by = "CODGEO")

# check again
head(geo)
summary(geo)

```


Assign lat and long values for NAs units:
```{r}
require(ggmap)

# [ delete? ]
# # compare numbers of NA in latitude and longitude 
# sum(is.na(geo$latitude)) - sum(is.na(geo$longitude))
# # check if they match or not
# sum(!is.na(geo$latitude[indNA_Long]))
# # 64 obs are missing in longitude but not in latitude, hence 88 vice versa

# index of NAs and their total
indNA_coord = is.na(geo$latitude) | is.na(geo$longitude)
sum(indNA_coord)

# NO MORE NEEDED BECAUSE IS A CSV FILE
    # # initialize variables
    # city_search = 0
    # res = as.data.frame(matrix(c(0, 0, 0), 1, 3))
    # names(res) = c("lon", "lat", "address")
    # 
    # # retrieve lat and long (Google API = 2500 request per day)
    # # my_iter = floor(sum(indNA_coord)/3)
    # for (i in 1:sum(indNA_coord)){
    # 
    #   # city searched
    #   city_search[i] = paste(c(as.character(NA_coord$town_name[i]), as.character(NA_coord$postal_code[i]), as.character(NA_coord$department[i]), "France"), sep=" ", collapse = ", ")
    #   
    #   # solution
    #   res[i,] = geocode(city_search[i], output = "latlona", source = c("google", "dsk"), messaging = FALSE)
    # 
    #   # retrieve still missing data, because of existing problems with API (up to 15 trials)
    #   j = 0
    #   while (any(is.na(res[i,])) & j < 25){
    #     res[i,] = geocode(city_search[i], output = "latlona", source = c("google", "dsk"), messaging = FALSE)
    #     j = j + 1
    #   }
    # }

    # # check the solution
    # sol = cbind(searched = city_search, res)

    # # save it as a csv file to save time
    # write.csv(retrieved_geo_NA[,2:3], "geo_NA_Final.csv", quote = FALSE, row.names=FALSE, fileEncoding = "UTF-8")
    

# read the created csv
retrieved_geo_NA = read.csv("geo_NA_Final.csv", header = T, encoding = "UTF-8")
# get only long and lat and assign to original NA 
geo$latitude[indNA_coord] = retrieved_geo_NA[,2]
geo$longitude[indNA_coord] = retrieved_geo_NA[,1]

# there are 37 still missing units, which are towns located in old colonies far from Europe
indNA_coord = is.na(geo$latitude) | is.na(geo$longitude)
sum(indNA_coord)
# exclude those towns
geo = geo[!indNA_coord,]

summary(geo)

```

## EDA ##

```{r}
#install.packages("ggplot2")
#install.packages("ggmap")
require(ggplot2)
require(ggmap)

# plot france (center: 2.213749 46.227638)
# fra_center = as.numeric(geocode("France"))
fra_center = c(2.213749, 46.227638)
FraMap = ggmap(get_googlemap(center=fra_center, scale=2, zoom=5), extent="normal")
FraMap

# plot all towns available
geo_pos = as.data.frame(cbind(lon = geo$longitude, lat = geo$latitude))
geo_pos = geo_pos[complete.cases(geo_pos),]
FraMap +
  geom_point(aes(x=lon, y=lat), data=geo_pos, col="orange", alpha=0.1) 

# delete non-European countries
ind_nonEur = geo$latitude < 30 | geo$latitude > 70 |geo$longitude < -20 | geo$longitude > 20
sum(ind_nonEur)
geo = geo[!ind_nonEur,]

# plot all European towns available
geo_pos = as.data.frame(cbind(lon = geo$longitude, lat = geo$latitude))
geo_pos = geo_pos[complete.cases(geo_pos),]
FraMap +
  geom_point(aes(x=lon, y=lat), data=geo_pos, col="orange", alpha=0.1) 

```



## What we have learned ##

Solved: 

* Why latitude is missing and not longitude?
* There are some duplications.

To do:

* What to do with non-European towns?



## How to use these data ##

* Compare European towns vs. old colonies?
* Useful for all datasets/analyses


# Analyze salary data #

## Pre-processing ##

```{r}
# preliminary checks
dim(salary)
names(salary)
head(salary)
str(salary)
summary(salary)

# Drop unnecessary columns (town name repeats in other table, is it surely possible to merge them?)
names(salary)
# salary <- subset(salary, select = -c(town))

# Convert CODGEO to numeric
salary$CODGEO <- as.numeric(as.character(salary$CODGEO))

# Check for duplicated data
sum(duplicated.data.frame(salary))


```


## EDA ##

Univariate analysis comparing various job categories for both genders:  
```{r}

require(ggplot2)

#  number of units
n_sex <- length(salary$sal_Females)

# vector representing males and females
Label <- c(rep("M", n_sex*5), rep("F", n_sex*5))

# vector representing the variable considered
Variable <- c(rep("General", n_sex), 
             rep("Executive", n_sex),
             rep("MidManager", n_sex),
             rep("Employee", n_sex),
             rep("Worker",n_sex),
             rep("General", n_sex), 
             rep("Executive", n_sex),
             rep("MidManager", n_sex),
             rep("Employee", n_sex),
             rep("Worker",n_sex))

# merge these data
sal_sex = cbind.data.frame(Label = Label, 
             value = c(salary$sal_Males, salary$sal_M_executive, salary$sal_M_midManager, salary$sal_M_employee, salary$sal_M_worker,
                       salary$sal_Females, salary$sal_F_executive, salary$sal_F_midManager, salary$sal_F_employee, salary$sal_F_worker),
             Variable = Variable)

# plotting phase
p <-  ggplot(data = sal_sex, aes(x=Label, y=value)) +
      geom_boxplot(aes(fill = Label)) +
      # not color points replacing colour = group instead of colour=Label
      geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75)) +
      facet_wrap( ~ Variable, scales="free") +
      xlab("Sex") + ylab("Mean net salary per hour") + ggtitle("Gender comparison for different job positions") +
      theme(plot.title = element_text(hjust = 0.5)) +      stat_boxplot(geom = "errorbar", width = 0.5)
      # p <- p + guides(fill=guide_legend(title="Legend"))
p

# excluding outliers
p <- ggplot(data = sal_sex, aes(x=Label, y=value)) +
      scale_y_continuous(limits = quantile(sal_sex$value, c(0, 0.9))) +
      geom_boxplot(aes(fill = Label)) +
      # not color points replacing colour = group instead of colour=Label
      geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75)) +
      facet_wrap( ~ Variable, scales="free") +
      xlab("Sex") + ylab("Mean net salary per hour") + 
      ggtitle("Gender comparison for different job positions excluding the last decile") +
      theme(plot.title = element_text(hjust = 0.5)) +
      # p <- p + guides(fill=guide_legend(title="Legend"))
      stat_boxplot(geom = "errorbar", width = 0.5)
p

# vector representing males and females
Label <- c(rep("M", n_sex*3), rep("F", n_sex*3))

# vector representing the variable considered
Variable <- c(rep("18-25", n_sex), 
              rep("26-50", n_sex),
              rep("51+", n_sex),
              rep("18-25", n_sex), 
              rep("26-50", n_sex),
              rep("51+", n_sex))

# merge these data
sal_sex = cbind.data.frame(Label = Label, 
                           value = c(salary$sal_M_18_25, salary$sal_M_26_50, salary$sal_M_51plus, 
                                     salary$sal_F_18_25, salary$sal_F_26_50, salary$sal_F_51plus),
                           Variable = Variable)

# plotting phase
p <-  ggplot(data = sal_sex, aes(x=Label, y=value)) +
  geom_boxplot(aes(fill = Label)) +
  # not color points replacing colour = group instead of colour=Label
  geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75)) +
  facet_wrap( ~ Variable, scales="free") +
  xlab("Sex") + ylab("Mean net salary per hour") + ggtitle("Gender comparison for different ages") +
  theme(plot.title = element_text(hjust = 0.5)) + ylim(c(5, 100)) +
  stat_boxplot(geom = "errorbar", width = 0.5)
# p <- p + guides(fill=guide_legend(title="Legend"))
p

```

[[[[TO modify]]]]
Focusing on possible social inequalities:
[[TAKEN from kernel of anqitu]]
Overall, there is obvious income inequality between genders, age groups and working social classes. On the average basis, the mean income for each town shows an increasing trend when age increases, showing that the salary increases when people work for longer time and their experience are valued by industries. The income inequality between genders shows the sign of gender discrimination in the society. The mean income for women is lowers than that of men for all age groups. Besides, while the mean income increases by age, the income difference between men and women also increases by age, showing that the income inequality between genders is more outstanding for the older age group. Since people at the older age group are likely to richer than the youngsters, coupled with the previous observation of aging population, there is a huge market potential for silver industry. Businesses can grab the opportunity in an aging society by identifying new customer segments among seniors and developing novel products and services to help them. Figure 5.
]]][[]]

```{r}
# Gender salary ratio and general level of income

# Overall mean salary
# The higher the net mean income, the more skewed the ratio of salary between female and male is.
# only 2 towns have a ratio>1
salary$salary_ratio_FvsM <- salary$sal_Females / salary$sal_Males
hist(salary$salary_ratio_FvsM)
ggplot(salary, aes(x= sal_general, y=salary_ratio_FvsM)) + 
  geom_point(size = 0.5, colour = "#0091ff")+
  geom_smooth()

# Executives mean salary
# a bit better and less skewed
salary$salary_ratio_FvsM_Exec <- salary$sal_F_executive / salary$sal_M_executive
hist(salary$salary_ratio_FvsM_Exec)
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_Exec)) + 
  geom_point(size = 0.5, colour = "#0091ff")+
  geom_smooth()

# Middle managers mean salary
# ..
salary$salary_ratio_FvsM_midManag <- salary$sal_F_midManager / salary$sal_M_midManager
hist(salary$salary_ratio_FvsM_midManag)
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_midManag)) + 
  geom_point(size = 0.5, colour = "#0091ff")+
  geom_smooth()

# Middle managers mean salary
# ..
salary$salary_ratio_FvsM_worker <- salary$sal_F_worker / salary$sal_M_worker
hist(salary$salary_ratio_FvsM_worker)
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_worker)) + 
  geom_point(size = 0.5, colour = "#0091ff")+
  geom_smooth()

# Employee mean salary
# ..
salary$salary_ratio_FvsM_employee <- salary$sal_F_employee / salary$sal_M_employee
hist(salary$salary_ratio_FvsM_employee)
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_employee)) + 
  geom_point(size = 0.5, colour = "#0091ff")+
  geom_smooth()


```


## Linear models ##


Highlight bivariate relations using scatter matrices:
```{r}
# most general pairs
pairs(salary[c(3:8, 13, 18:20)])
# pairs highlighting genders' differences
pairs(salary[c(9:12, 14:17)])
```

Fit a regression model to predict the salaries of people in age 26-50 using as regressor 51+ years:
```{r, fig.keep='all'}

# fit and show OLS estimate
plot(salary$sal_26_50 ~ salary$sal_51plus)
fit_LM_26_50 = glm(salary$sal_26_50 ~ salary$sal_51plus, data = salary)
abline(fit_LM_26_50, lwd=3, col="red")

# diagnostics
summary(fit_LM_26_50)
plot(fit_LM_26_50)
```

Same as before but adding polynomials which are evauated using 10-folds cross validation:

```{r, fig.keep='all'}

require(boot)
set.seed(1)

# k-Fold Cross-Validation
cv.err.K = rep(0, 5)
cv.err.K = rbind(cv.err.K, cv.err.K)
for (i in 1:5){
  fit_LM_26_50.K = glm(sal_26_50 ~ poly(sal_51plus, i), data = salary)
  cv.err.K[,i] = cv.glm(salary, fit_LM_26_50.K, K = 10)$delta[1]
}

# plotting results
plot(cv.err.K[1,], type = 'l', col = 'red', xlab = "Polynomials' order", 
     ylab = "10-folds CV", main = "CV and adjusted CV for different polynomials")
lines(cv.err.K[2,], col = 'green')
points(which.min(cv.err.K), cv.err.K[1, which.min(cv.err.K)], col = "red", cex=2, pch=20)
legend('topright', legend = c('CV', 'Adj. CV'), col = c('red', 'green'), pch = 10)

```


Predicting sal_executive with 5 regressers using Lasso with CV and 10-folds CV:
[ PROBLEM FOR COLLINEARITY? use ridge?] [ add polynomials? ]
```{r, fig.keep='all'}

require(glmnet)
set.seed(1)

# crate an X matrix excluding intercept
# x = cbind(salary$sal_midManager, salary$sal_employee, salary$sal_worker, salary$sal_18_25, salary$sal_51plus)
# y = salary$sal_executive
# probably for ridge
names(salary)
y = salary$sal_26_50
x = as.matrix(cbind(salary[, c(4:8, 13, 18, 20)]))
names(x)

# grid for lambda values
grid = 10^seq(1, -5, length = 100)
lasso.mod = glmnet(x, y, alpha = 1, lambda = grid)
dim(coef(lasso.mod))
# the norms are increasing in value because of the shrinkage
lasso.mod$lambda[1]                  # lambda value
sqrt(sum(coef(lasso.mod)[-1,1]^2))   # L2 norm of its coeff
lasso.mod$lambda[51]
sqrt(sum(coef(lasso.mod)[-1,51]^2))
lasso.mod$lambda[90]
sqrt(sum(coef(lasso.mod)[-1,90]^2))
# predict values for a new lambda, e.g. OLS
OLS = predict(lasso.mod, s = 0, type = "coefficients")[1:nrow(coef(lasso.mod)),]

# split the date leaving the 10% for CV
train = sample(1:nrow(salary), floor(nrow(salary)*0.9))
test = -train
y.test = y[test]
lasso.mod = glmnet(x[train,], y[train], alpha = 1, lambda = grid, thresh = 1e-12)
err.i = rep("NA", length(grid))
for (i in 1:length(grid)){
  lasso.pred = predict(lasso.mod, s = grid[i], newx = x[test,])
  err.i[i] = mean((lasso.pred - y.test)^2)
}
plot(log(grid), err.i, xlab = 'log Lambda', ylab = 'test set MSE', 
     main = 'Test MSE among different Lambdas', ylim = c(0, 10))
bestlam = grid[which.min(err.i)]
points(log(grid)[bestlam], err.i[bestlam], col ="red", cex=2, pch=20)
# high values of lambda are like fitting just the intercept

# using 10 folds CV
set.seed (1)
cv.out = cv.glmnet(x[train ,], y[train], alpha = 1)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
lasso.pred = predict(lasso.mod, s=bestlam, newx=x[test ,])
mean((lasso.pred - y.test)^2)


# using best subset
require(leaps)
dataBS = as.data.frame(cbind(y, x))
best.sub = regsubsets(y ~ x, data = dataBS, nvmax = nrow(coef(lasso.mod)))
best.sub.summary = summary(best.sub)
names(best.sub.summary)
# manual plotting
par(mfrow =c(2,2))
# rsq
plot(best.sub.summary$rsq , xlab="Number of Variables", ylab="Rsq", type="l")
ind_Rsq = which.max(best.sub.summary$rsq)
points(ind_Rsq, best.sub.summary$adjr2[ind_Rsq], col ="red", cex=2, pch=20)
# adjRsq
plot(best.sub.summary$adjr2 ,xlab="Number of Variables", ylab="Adjusted RSq", type="l")
ind_adjRsq = which.max(best.sub.summary$adjr2)
points(ind_adjRsq, best.sub.summary$adjr2[ind_adjRsq], col ="red", cex=2, pch=20)
# Cp
plot(best.sub.summary$cp ,xlab="Number of Variables", ylab="Cp", type="l")
ind_Cp = which.min(best.sub.summary$cp)
points(ind_Cp, best.sub.summary$cp[ind_adjRsq], col ="red", cex=2, pch=20)
# bic
plot(best.sub.summary$bic ,xlab="Number of Variables", ylab="bic", type="l")
ind_bic = which.min(best.sub.summary$bic)
points(ind_bic, best.sub.summary$bic[ind_bic], col ="red", cex=2, pch=20)
# built-in plots
?plot.regsubsets
par(mfrow=c(1,1))
plot(best.sub, scale = "r2")
plot(best.sub, scale = "adjr2")
plot(best.sub, scale = "Cp")
plot(best.sub, scale = "bic")
# retrieve the model with min BIC
coefficients(best.sub, which.min(best.sub.summary$bic))

```




Model salaries for people aged 18-25, which seems more difficult to predict:
```{r, fig.keep='all'}

plot(y = salary$sal_18_25, x = salary$sal_51plus)
# there is a clear outlier
ind_out = which(salary$sal_18_25 == max(salary$sal_18_25))
# check if is so in all dimensions (apparently not)
col_col <- rep("black", nrow(salary))
col_col[ind_out] <- "red"
pairs(salary[, c(3:8, 13, 18:20)], col = col_col)

# evaluate an OLS fit
fit_LM_18_25 = lm(salary$sal_18_25 ~ salary$sal_51plus)
plot(y = salary$sal_18_25, x = salary$sal_51plus)
abline(fit_LM_18_25, lwd=3, col="red")

# # using more predictors
# fit_LM_2 = lm(salary$sal_M_18_25 ~ salary$sal_26_50 + salary$sal_51plus + salary$sal_general + salary$sal_executive + 
#                 salary$sal_midManager + salary$sal_employee + salary$sal_worker)
# 
# summary(fit_LM_2)
```

ANOVA model for salary:
```{r}

# create response variable
sal_y = c(salary$sal_M_18_25, salary$sal_M_26_50, salary$sal_M_51plus,
        salary$sal_M_executive, salary$sal_M_midManager, salary$sal_M_employee, salary$sal_M_worker,
        salary$sal_F_18_25, salary$sal_F_26_50, salary$sal_F_51plus,
        salary$sal_F_executive, salary$sal_F_midManager, salary$sal_F_employee, salary$sal_F_worker)

hist(sal_y, 30)
hist(log(sal_y), 30)
hist(sal_y^-1, 30)
sal_y = sal_y^-1  # also suggested by Box-Cox transformation

n_sal_y = length(sal_y)             # length response variable
n_cat = length(salary$sal_M_18_25)  # length of each category (i.e., original vectors)

# create sex dummy variable, 1 for males and 0 for females
sal_sex = rep(0, n_sal_y)   # full regressors
sal_sex[1:n_sal_y/2] = 1    # assign males

# create age dummy variables, 18-25 years old is the base case
sal_age = cbind(rep(0, n_sal_y), rep(0, n_sal_y)) # full regressors
# 26-50 y.o.
sal_age[(n_cat+1):(n_cat*2), 1] = 1     # males
sal_age[(n_cat*8+1):(n_cat*9), 1] = 1   # females
# 51+ y.o.
sal_age[(n_cat*2+1):(n_cat*3), 2] = 1   # males
sal_age[(n_cat*9+1):(n_cat*10), 2] = 1  # females

# create job type dummy variables, worker is the base case
sal_job = cbind(rep(0, n_sal_y), rep(0, n_sal_y), rep(0, n_sal_y)) # full regressors
# executives
sal_job[(n_cat*3+1):(n_cat*4), 1] = 1     # males
sal_job[(n_cat*10+1):(n_cat*11), 1] = 1   # females
# middle managers
sal_job[(n_cat*4+1):(n_cat*5), 2] = 1     # males
sal_job[(n_cat*11+1):(n_cat*12), 2] = 1   # females
# employee
sal_job[(n_cat*5+1):(n_cat*6), 3] =   1   # males
sal_job[(n_cat*12+1):(n_cat*13), 3] = 1   # females

# final data set
data_ANOVA = cbind.data.frame(response = sal_y, sex = sal_sex, age = sal_age, job = sal_job)
names(data_ANOVA)
# show regressors' shape
if(!require(rafalib)){install.packages("rafalib")}
imagemat(data_ANOVA[,-1])

# ANOVA model
sal_ANOVA = lm(sal_y ~ sal_sex + sal_age + sal_job + sal_sex:sal_age + sal_sex:sal_job)
summary(sal_ANOVA)
anova((sal_ANOVA))

# box-cox transformation suggested to use y^-1
if(!require(MASS)){install.packages("MASS")}
boxcox(sal_ANOVA)

# adding contrasts?
# add CV and LASSO!
```


PCA for salary:
```{r}
myPr <- prcomp(salary[, 3:26], scale = TRUE)
myPr
summary(myPr)
plot(myPr, type = "l")
biplot(myPr, scale = 0, cex = 0.5)
str(myPr)
#myPr$x #checking principal component scores
salary2 <- cbind(salary, myPr$x[, 1:2])
head(salary2)
#plot with ggplot...
#require(ggplot2)
ggplot(salary2, aes(PC1, PC2)) + 
  stat_ellipse(geom = "polygon", col = "black", alpha = 0.5) + 
  geom_point(shape = 21, col = "black")
# correlations between variables and PCs...
cor(salary[, 3:26], salary2[,27:28])
```


## What we have learned ##

* Check the outlier in sal_18_25: which city is it, etc.
* evaluate possible multicollinearity
* Try a regression with all predictors ans lasso

## How to use these data ##

* ...


# Analyze population data #

## Pre-processing ##


```{r}
# preliminary checks
names(population)
summary(population)

# Drop unnecessary columns (NIVGEO is the same for all)
population <- subset(population, select = -c(NIVGEO, LIBGEO))

# converting CODGEO to numeric
population$CODGEO <- as.numeric(population$CODGEO)

# Refactor sex and MOCO
population$MOCO <- factor(population$MOCO, levels = c(11,12,21,22,23,31,32),
                          labels = c("children_living_with_two_parents", "children living with one parent",
                                     "adults_living_in_couple_without_child", "adults_living_in_couple_with_children",
                                     "adults_living_alone_with_children","persons not from family living in the home",
                                     "persons_living_alone"))
population$sex <- factor(population$sex, levels = c(1,2), labels = c("Male", "Female"))
head(population)
# Take out rows with NB (number of people in this category) equal to 0
population <- population[population$peopleCategNum != 0,]

head(population)
summary(population)


```

## EDA ##
```{r}
#Compare age categories:
#library(ggplot2)
#  number of units
n_cat <- length(population$CODGEO)
# extract unique categories
uniq_cat <- unique(population$ageCateg5!=5)
# vector representing sex for each category
Label <- c(rep(c('Male', 'Female'), n_cat))
# vector representing the variable considered
Variable <- rep(uniq_cat, n_cat/length(uniq_cat))
Value=population$peopleCategNum
# merge these data
#pop_categ = cbind.data.frame(Label = Label, 
#             value = Value,
#             Variable = Variable)
#p <- ggplot(data = pop_categ, aes(x=Label, y=value)) 
#p <- p + geom_boxplot(aes(fill = Label))
# if you want color for points replace group with colour=Label
#p <- p + geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75))
#p <- p + facet_wrap( ~ Variable, scales="free")
#p <- p + xlab("x-axis") + ylab("y-axis") + ggtitle("Category comparison")
# p <- p + guides(fill=guide_legend(title="Legend"))
#p
```

```{r}
# Restructure population data to produce the demographic profile per town
# install.packages("plyr")
library(plyr)
population_per_town_data <- ddply(population, .(CODGEO), function(population) {
  data.frame(total_population = sum(population$peopleCategNum),
             male = sum(population[population$sex == "Male",]$peopleCategNum),
             female = sum(population[population$sex == "Female",]$peopleCategNum),
             child = sum(population[population$ageCateg5 %in% seq(0, 10, by=5),]$peopleCategNum),
             elderly = sum(population[population$ageCateg5 %in% seq(65, 80, by=5),]$peopleCategNum),
             workforce = sum(population[population$ageCateg5 %in% seq(15, 60, by=5),]$peopleCategNum) 
  )})

population_per_town_data$dependent <- population_per_town_data$child + population_per_town_data$elderly
population_per_town_data$sex_ratio <- ifelse(population_per_town_data$female==0, 0, population_per_town_data$male / population_per_town_data$female)
population_per_town_data$dependency_ratio <- ifelse(population_per_town_data$workforce==0, 0, population_per_town_data$dependent / population_per_town_data$workforce)
population_per_town_data$aged_dependency_ratio <- ifelse(population_per_town_data$workforce==0, 0, population_per_town_data$elderly / population_per_town_data$workforce)
population_per_town_data$child_dependency_ratio <- ifelse(population_per_town_data$workforce==0, 0, population_per_town_data$child / population_per_town_data$workforce)
summary(population_per_town_data)
```

```{r}
# Scale population to log
hist(population_per_town_data$total_population, ylim=c(0,40000), breaks = seq(0, 2500000, by=250000), xlab="", main = "", labels=T, col ="light blue")
population_per_town_data$total_population_log <- log10(population_per_town_data$total_population)

# Merge geo and pop
geo_pop_by_town <- merge(geo, population_per_town_data)
summary(geo_pop_by_town)


# Plot "Distribution of Population for each Town"
#myPalette(low = "white", high = c("green", "red"), mid=NULL, k =50)-Need "GLAD" package
sc <- scale_colour_gradientn(colours =palette(rainbow(8)), limits=c(min(geo_pop_by_town$total_population_log), max(geo_pop_by_town$total_population_log)))
poppulation_distribution <- 
  FraMap + 
  geom_point(aes(x=geo_pop_by_town$longitude, y=geo_pop_by_town$latitude, colour=geo_pop_by_town$total_population_log), 
             data=geo_pop_by_town, alpha=0.8, size=0.6) + 
  sc +
  #geom_text(aes(label = town_name, x = longitude, y = latitude), 
            #data = subset(geo_pop_by_town, total_population_log %in% head(sort(total_population_log, decreasing=TRUE), 3)), check_overlap = TRUE, size=7) +

  labs(color='Total Population in Log') +
  ggtitle("Distribution of Population for each Town") 
poppulation_distribution
```

```{r}
# Group population data by department because of small size of some towns and the given geojson file of department
pop_by_department <- ddply(geo_pop_by_town, .(department), function(geo_pop_by_town) {
  data.frame(total_population = sum(geo_pop_by_town$total_population),
             male = sum(geo_pop_by_town$male),
             female = sum(geo_pop_by_town$female),
             child = sum(geo_pop_by_town$child),
             elderly = sum(geo_pop_by_town$elderly),
             dependent = sum(geo_pop_by_town$dependent),
             workforce = sum(geo_pop_by_town$workforce) 
  )})

summary(pop_by_department)
pop_by_department$dependency_ratio <- pop_by_department$dependent / pop_by_department$workforce
pop_by_department$aged_dependency_ratio <- pop_by_department$elderly / pop_by_department$workforce
pop_by_department$child_dependency_ratio <- pop_by_department$child / pop_by_department$workforce
```

```{r}
# Scale population to log
pop_by_department$total_population_log <- log10(pop_by_department$total_population)

# Merge geo and pop
geo_pop_by_department <- merge(geo, pop_by_department)
summary(geo_pop_by_department)
```


```{r}
# Plot "Distribution of Population for each department"
#myPalette(low = "white", high = c("green", "red"), mid=NULL, k =50)-Need "GLAD" package
sc <- scale_colour_gradientn(colours =palette(rainbow(8)), limits=c(min(geo_pop_by_department$total_population_log), max(geo_pop_by_department$total_population_log)))
pop_distribution_department <- 
  FraMap + 
  geom_point(aes(x=geo_pop_by_department$longitude, y=geo_pop_by_department$latitude, colour=geo_pop_by_department$total_population_log), 
             data=geo_pop_by_department, alpha=0.8, size=0.6) + 
  sc +
  #geom_text(aes(label = town_name, x = longitude, y = latitude), 
            #data = subset(geo_pop_by_department, total_population_log %in% head(sort(total_population_log, decreasing=TRUE), 3)), check_overlap = TRUE, size=7) +
  labs(color='Total Population in Log') +
  ggtitle("Distribution of Population for each department") 
pop_distribution_department
```



# Produce consistent datasets #

 
```{r}

# use only integer values
geo$CODGEO = as.integer(geo$CODGEO)  # already integer
population$CODGEO = as.integer(population$CODGEO)
firms$CODGEO = as.integer(firms$CODGEO)
salary$CODGEO = as.integer(salary$CODGEO)

# install.packages("dplyr")
library(dplyr)
dataset = c("population", "salary", "firms", "geo")

# obtain sommon IDs for all datasets
for (i in dataset){
  # get i-th name and make a new variable adding NEW
  nam <- paste(i, "NEW", sep = "")
  # counter to identify the number of iteration in j
  iter = 1
  for (j in dataset){
    if (j != i){
      # datasets different from i-th
      if (iter == 1){
        # 1st iteration: use the original dataset (e.g., geo)
        assign(nam, semi_join(get(i), get(j), by = "CODGEO"))
      } else{
        # successive iteration: use the new dataset (e.g., geoNEW)
        assign(nam, semi_join(get(nam), get(j), by = "CODGEO"))
      }
      iter = iter + 1
    }
  }
}

# check how many observation have been deleted
for (i in dataset){
  del_rows = nrow(get(i)) - nrow(get(paste(i, "NEW", sep = "")))
  del_prop = del_rows / nrow(get(paste(i, "NEW", sep = "")))
  del_obs = paste("For", i, del_rows, "have been deleted.",
                  "They were the", round(del_prop, digits=2), "% of the total.", sep = " ")
  print(del_obs)
}

```

```{r}
#populationNEW
summary(populationNEW)
population = populationNEW

# Restructure population data to produce the demographic profile per town
# install.packages("plyr")
library(plyr)
library(dplyr)
population_per_town_data <- ddply(population, .(CODGEO), function(population) {
  data.frame(total_population = sum(population$peopleCategNum),
             male = sum(population[population$sex == "Male",]$peopleCategNum),
             female = sum(population[population$sex == "Female",]$peopleCategNum),
             child = sum(population[population$ageCateg5 %in% seq(0, 10, by=5),]$peopleCategNum),
             elderly = sum(population[population$ageCateg5 %in% seq(65, 80, by=5),]$peopleCategNum),
             workforce = sum(population[population$ageCateg5 %in% seq(15, 60, by=5),]$peopleCategNum) 
  )})

population_per_town_data$dependent <- population_per_town_data$child + population_per_town_data$elderly
population_per_town_data$sex_ratio <- ifelse(population_per_town_data$female==0, 0, population_per_town_data$male / population_per_town_data$female)
population_per_town_data$dependency_ratio <- ifelse(population_per_town_data$workforce==0, 0, population_per_town_data$dependent / population_per_town_data$workforce)
population_per_town_data$aged_dependency_ratio <- ifelse(population_per_town_data$workforce==0, 0, population_per_town_data$elderly / population_per_town_data$workforce)
population_per_town_data$child_dependency_ratio <- ifelse(population_per_town_data$workforce==0, 0, population_per_town_data$child / population_per_town_data$workforce)
summary(population_per_town_data)
```

```{r}
# Scale population to log
hist(population_per_town_data$total_population, ylim=c(0,40000), breaks = seq(0, 2500000, by=250000), xlab="", main = "", labels=T, col ="light blue")
population_per_town_data$total_population_log <- log10(population_per_town_data$total_population)

# Merge geo and pop
geo_pop_by_town <- merge(geo, population_per_town_data)
summary(geo_pop_by_town) 
```

```{r}
# Plot "Distribution of Population for each Town"
#myPalette(low = "white", high = c("green", "red"), mid=NULL, k =50)-Need "GLAD" package
sc <- scale_colour_gradientn(colours =palette(rainbow(8)), limits=c(min(geo_pop_by_town$total_population_log), max(geo_pop_by_town$total_population_log)))
population_distribution <- 
  FraMap + 
  geom_point(aes(x=geo_pop_by_town$longitude, y=geo_pop_by_town$latitude, colour=geo_pop_by_town$total_population_log), 
             data=geo_pop_by_town, alpha=0.8, size=0.6) + 
  sc +
  #geom_text(aes(label = town_name, x = longitude, y = latitude), 
            #data = subset(geo_pop_by_town, total_population_log %in% head(sort(total_population_log, decreasing=TRUE), 3)), check_overlap = TRUE, size=7) +
  labs(color='Total Population in Log') +
  ggtitle("Distribution of Population for each Town") 
population_distribution
summary(population_distribution)

geo_pop_by_town[which.max(geo_pop_by_town$total_population_log),]
```

```{r}
# Group population data by department because of small size of some towns and the given geojson file of department
pop_by_department <- ddply(geo_pop_by_town, .(department), function(geo_pop_by_town) {
  data.frame(total_population = sum(geo_pop_by_town$total_population),
             male = sum(geo_pop_by_town$male),
             female = sum(geo_pop_by_town$female),
             child = sum(geo_pop_by_town$child),
             elderly = sum(geo_pop_by_town$elderly),
             dependent = sum(geo_pop_by_town$dependent),
             workforce = sum(geo_pop_by_town$workforce) 
  )})

summary(pop_by_department)
pop_by_department$dependency_ratio <- pop_by_department$dependent / pop_by_department$workforce
pop_by_department$aged_dependency_ratio <- pop_by_department$elderly / pop_by_department$workforce
pop_by_department$child_dependency_ratio <- pop_by_department$child / pop_by_department$workforce
```

```{r}
# Scale population to log
pop_by_department$total_population_log <- log10(pop_by_department$total_population)

# Merge geo and pop
geo_pop_by_department <- merge(geo, pop_by_department)
summary(geo_pop_by_department)
```

```{r}
# Plot "Distribution of Population for each department"
#myPalette(low = "white", high = c("green", "red"), mid=NULL, k =50)-Need "GLAD" package
sc <- scale_colour_gradientn(colours =palette(rainbow(8)), limits=c(min(geo_pop_by_department$total_population_log), max(geo_pop_by_department$total_population_log)))
pop_distribution_department <- 
  FraMap + 
  geom_point(aes(x=geo_pop_by_department$longitude, y=geo_pop_by_department$latitude, colour=geo_pop_by_department$total_population_log), 
             data=geo_pop_by_department, alpha=0.8, size=0.6) + 
  sc +
  #geom_text(aes(label = town_name, x = longitude, y = latitude), 
            #data = subset(geo_pop_by_department, total_population_log %in% head(sort(total_population_log, decreasing=TRUE), 3)), check_overlap = TRUE, size=7) +
  labs(color='Total Population in Log') +
  ggtitle("Distribution of Population for each department") 
pop_distribution_department
```

```{r}
population_data2 <- ddply(population, .(sex, ageCateg5), function(population) {
  data.frame(total_population = sum(population$peopleCateNum))
  })
pop_pyramid <- ggplot(data = population_data2, 
       mapping = aes(x = ageCateg5, fill = sex, 
                     y = ifelse(test = sex == "Male", 
                                yes = -total_population, no = total_population))) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = abs, limits = max(population_data2$total_population) * c(-1,1)) +
  labs(y = "Population") +
  coord_flip()
pop_pyramid

```

# Analysis #
```{r}

```
## PCA ##
```{r}

```
## Regression ##
```{r}
```
## Clustering ##
```{r}


```