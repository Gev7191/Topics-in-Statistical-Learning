---
title: "TSL Project"
author: "Luca Insolia, Jisu Kim and Gevorg Yeghikyan"    
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output:
  html_notebook:
    toc: yes
    toc_depth: '3' 
    highlight: tango
    keep_tex: yes
    number_sections: yes
  html_document:
    theme: united
    highlight: tango    
    toc: yes
    toc_depth: '3' 
#   pdf_document: # ADD PDF!
#     toc: yes
#     toc_depth: '3'
#     keep_tex: true
#     latex_engine: pdflatex
# editor_options:
#   # toc: yes
#   # toc_depth: 3
#   chunk_output_type: inline
---


# General information 

We analyze a dataset published on [Kaggle](https://www.kaggle.com/etiennelq/french-employment-by-town).
It refers to french employment, salaries, population per town. 
The aim is to evaluate equality/inequalities in France, and geographical distribution of business according to their size.

Such data are collected by the INSEE.
Information regarding the number of firms in every french town, categorized by size
can be found [here](https://www.insee.fr/fr/metadonnees/definition/c1135). This dataset contains about 35000 units/per town.

Information about salaries around french town per job categories, age and sex (expressed in average net amount per hour in euro) can be found [here](https://www.insee.fr/fr/statistiques/2522515). This dataset contains about 5000 units/per town. 

Demographic information in France per town, age, sex and living mode
can be found [here](https://www.insee.fr/fr/statistiques/2863607). This dataset contains about 8 million units/per town. Additional info about Population Data can be found [here](https://www.insee.fr/fr/statistiques/2863607#dictionnaire). 

These datasets have been pre-processed and put together. The final dataset contains 58 variables and 5022 observations. 


## Aim of the study 

This project aims to explore structure of French labour market. 
In particular, we are interested in:

* evaluating possible inequalities: per towns/region, sex, age, job categories etc.;
* discover geographical distribution of business according to their size
* predicting the ... using a regression model;
* reduce the dimensionality of ... performing a PCA;
* explore different algorithms to cluster male/females using ...


## Plan for the study 

1. Unsupervised learning: 
* PCA
* Clustering methods (K-means/Hierarchical)
2. Supervised learning:
* Linear/Quadratic Discriminant Analysis
* KNN
* Cross-validation
* Bootstrap
* Subset selection 
* Shrinkage methods
* Dimension reduction methods
3. Description of population demographics in France
4. Structure of the french labour market
5. ...
6. Future works


# General pre-processing phase 

Loading all libraries needed throughout the notebook:
```{r loading libraries}

# data manipulation
if(!require(plyr)){install.packages("dplyr"); library(plyr)}
if(!require(dplyr)){install.packages("dplyr"); library(dplyr)}
# plotting
if(!require(ggplot2)){install.packages("ggplot2"); library(ggplot2)}
if(!require(ggmap)){install.packages("ggmap"); library(ggmap)}
if(!require(ggbiplot)){
  if(!require(devtools)){
    install.packages("devtools")}
  install_github("vqv/ggbiplot")
  library(ggbiplot)}
if(!require(corrplot)){install.packages("corrplot"); library(corrplot)}
if(!require(zoo)){install.packages("zoo"); library(zoo)}
# Mclust clustering
if(!require(mclust)){install.packages("mclust"); library(mclust)}
# plot design matrix
if(!require(rafalib)){install.packages("rafalib"); library(rafalib)}
# cross validation
if(!require(boot)){install.packages("boot"); library(boot)}
# elastic net
if(!require(glmnet)){install.packages("glmnet"); library(glmnet)}
# group Lasso
if(!require(gglasso)){install.packages("gglasso"); library(gglasso)}

# box-cox tranformation (in ANOVA)
# if(!require(MASS)){install.packages("MASS"); library(MASS)}
# plot for PCA
# if(!require(factoextra)){install.packages("factoextra"); library(factoextra)}

```


Import the four main datasets:
```{r load datasets, warning=FALSE}

setwd("./data")
firms       <- read.csv("base_etablissement_par_tranche_effectif.csv", encoding = "UTF-8")
geo         <- read.csv("name_geographic_information.csv", encoding = "UTF-8")
salary      <- read.csv("net_salary_per_town_categories.csv", encoding = "UTF-8")
population  <- read.csv("population.csv", encoding = "UTF-8")

```

Check variables' names:
```{r original names}

names(firms) 
names(population)
names(salary)
names(geo)

```


Assign meaningful names and drop some variables which are not needed:
```{r assign names}

names(firms)[2:ncol(firms)] <-
  c("town", 
    "regNum",
    "deptNum",
    "total",
    "null",
    "firmsEmpl_1_5",
    "firmsEmpl_6_9",
    "firmsEmpl_10_19",
    "firmsEmpl_20_49",
    "firmsEmpl_50_99",
    "firmsEmpl_100_199",
    "firmsEmpl_200_499",
    "firmsEmpl_500plus")

names(salary)[2:ncol(salary)] <-
  c("town",
    "sal_general",    
    "sal_executive",
    "sal_midManager",
    "sal_employee",
    "sal_worker",
    "sal_Females",
    "sal_F_executive",
    "sal_F_midManager",
    "sal_F_employee",
    "sal_F_worker",
    "sal_Males",
    "sal_M_executive",
    "sal_M_midManager",
    "sal_M_employee",
    "sal_M_worker",
    "sal_18_25",
    "sal_26_50",
    "sal_51plus",
    "sal_F_18_25",
    "sal_F_26_50",
    "sal_F_51plus",
    "sal_M_18_25",
    "sal_M_26_50",
    "sal_M_51plus")

names(population)[5:7] <-
  c("ageCateg5",
    "sex",
    "peopleCategNum")

names(geo)[2:11] =
  c("code_region",
    "region", 
    "region_capital",
    "number_depart",
    "department", 
    "prefecture",
    "circons",
    "town_name", 
    "postal_code", 
    "CODGEO")

names(geo)[14] =
  c("eloignement")

# Drop unnecessary columns (code/num and name represents same thing) 
geo <- subset(geo, select = -c(EU_circo, code_region, number_depart, prefecture, circons, eloignement))

```

Check new variables' names:
```{r new names}

names(firms) 
names(population)
names(salary)
names(geo)

```


## Additional notes 

* Keep Department number?

* Eloignement is the distance from where?



# Analyze firms data 

## Pre-processing:

Categorize firms' size according to [EU standard](http://ec.europa.eu/eurostat/statistics-explained/index.php/Glossary:Enterprise_size), but in a slightly different form for medium and large firms (i.e., medium firms have <200 instead of <250 employees):

```{r pre processing firms}

# preliminary checks
dim(firms)
names(firms)
head(firms)
str(firms)
summary(firms)

# No duplicated data
sum(duplicated.data.frame(firms))

# merge variables
firms$micro   <- firms$firmsEmpl_1_5 + firms$firmsEmpl_6_9
firms$small   <- firms$firmsEmpl_10_19 + firms$firmsEmpl_20_49
firms$medium  <- firms$firmsEmpl_50_99 + firms$firmsEmpl_100_199
firms$large   <- firms$firmsEmpl_200_499 + firms$firmsEmpl_500plus

# Drop unnecessary (at the moment) columns 
firms <- subset(firms, select = c(CODGEO, town, total, micro, small, medium, large, null))

# check
head(firms)
summary(firms)
str(firms)

```

## Descriptive statistics 

Check the distribution of the null firms (i.e., unknown sizes) and analyze
firms' distribution per town:
  
```{r firms distribution}

# there is an obs with more than 316K null data: we check if it is plausible
# get the highest 20 null values
str_firms <- sort(firms$null, decreasing = T)[1:20]
# get their indexes
str_firms_ind <- match(str_firms, firms$null)
# get the corresponding city
firms$town[str_firms_ind]
# it is about the largest cities, hence it seems reasonable..

# check the ratio of null firms for each town
summary(firms$null/firms$total)
# a lot of information is missing
# should we remove these data?
hist(firms$null/firms$total)
ggplot(data=firms, aes(firms$null/firms$total)) +
  geom_histogram(aes(y =..count..), col="black", fill="blue", alpha = .3, bins = 50) +
  labs(x="Null firms/total firms", y="Count") +
  ggtitle("Ratio between the number of null firms and total firms per town") +
  theme(plot.title = element_text(hjust = 0.5)) 

# evaluate the distribution of all the sizes 
ggplot(data=firms, aes(log(firms$total))) +
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) +
  geom_density(col="black") +
  labs(x="Number of firms (log scale)", y="Density") +
  ggtitle("Total number of firms per town") +
  theme(plot.title = element_text(hjust = 0.5)) 

ggplot(data=firms, aes(log(firms$null))) +
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) +
  geom_density(col="black") +
  labs(x="Number of firms of unknown size (log scale)", y="Density") +
  ggtitle("Number of firms of unknown size per town") +
  theme(plot.title = element_text(hjust = 0.5))

ggplot(data=firms, aes(log(firms$micro))) +
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) +
  geom_density(col="black") +
  labs(x="Number of firms of micro size (log scale)", y="Density") +
  ggtitle("Number of firms of micro size per town") +
  theme(plot.title = element_text(hjust = 0.5))



ggplot(data=firms, aes(log(firms$small))) +
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) +
  geom_density(col="black") +
  labs(x="Number of firms of small size (log scale)", y="Density") +
  ggtitle("Number of firms of small size per town") +
  theme(plot.title = element_text(hjust = 0.5))


ggplot(data=firms, aes(log(firms$medium))) +
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) +
  geom_density(col="black") +
  labs(x="Number of firms of medium size (log scale)", y="Density") +
  ggtitle("Number of firms of medium size per town") +
  theme(plot.title = element_text(hjust = 0.5))


ggplot(data=firms, aes(log(firms$large))) +
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) +
  geom_density(col="black") +
  labs(x="Number of firms of large size (log scale)", y="Density") +
  ggtitle("Number of firms of large size per town") +
  theme(plot.title = element_text(hjust = 0.5))

```

## PCA 

PCA on firms data:

```{r PCA}

# pairs(firms[, 3:8])
# 
# salary_NEW = salary[, 3:ncol(salary)]
# # colnames(salary_NEW) = 1:32
# corrplot(cor(salary_NEW), method = "circle", title = "Correlation matrix for salary", 
#          diag = T, tl.cex=0.5, type="lower", #col = colorRampPalette(c("red","green","navyblue"))(100))
#          tl.col = "black", mar=c(0,0,1,0)) 
# 
# 
# # firms_clean <- firms[firms$micro < 20000 & firms$large < 200,]
# firms_clean <- firms[firms$micro > 1 & firms$micro < 2500 & 
#                      firms$small > 1 & firms$small < 800 & 
#                      firms$medium > 1 & firms$medium < 500 & 
#                      firms$large > 1 & firms$large < 200 &
#                      firms$null > 1 & firms$null < 2000 ,]
# myPr <- prcomp(firms_clean[, 4:8], scale = TRUE)
# #plot(scale(firms_clean$micro), scale(firms_clean$large))
# #mean(firms_clean$micro)
# #mean(firms_clean$large)
# myPr
# summary(myPr)
# plot(myPr, type = "l")
# # biplot(myPr, scale = 0)
# #extract PC scores...
# str(myPr)
# #myPr$x #checking principal component scores
# firms2 <- cbind(firms_clean, myPr$x[, 1:2])
# head(firms2)
# #plot with ggplot...
# ggplot(firms2, aes(PC1, PC2)) +
#   stat_ellipse(geom = "polygon", col = "black", alpha = 0.5) +
#   geom_point(shape = 21, col = "black")
# # correlations between variables and PCs...
# cor(firms_clean[, 4:8], firms2[,9:10])
# 
# # using ggbiplot
# ggbiplot(myPr, obs.scale = 1, var.scale = 1, varname.size = 5.5, varname.adjust = 1) +
#   ggtitle("Biplot for the firms's size") +
#   theme(plot.title = element_text(hjust = 0.5))
```

Modified PCA [Luca]:
```{r PCA 2}

# get Paris in order to exclude it in the following
Paris = which.max(firms$total)

# Original scale
# Scatter matrix
pairs(firms[-Paris, 3:8], gap=0, main = "Scatter matrix for firms")
# Correlation matrix
corrplot(cor(firms[-Paris, 3:8]), method = "number", title = "Correlation matrix for firms", 
         diag = F, tl.cex=1, #col = colorRampPalette(c("red","green","navyblue"))(100))
         tl.col = "black", mar=c(0,0,1.5,0))

# Log scale
# Scatter matrix
pairs(firms[-Paris, 3:8], log = "xy", gap=0, main = "Scatter matrix for firms in log scale")
# Correlation matrix
firmsLog = log(firms[, 3:8]) 
firmsLog[firmsLog == -Inf] = 0
corrplot(cor(firmsLog), method = "number", title = "Correlation matrix for firms  in log scale", 
          diag = F, tl.cex=1, #col = colorRampPalette(c("red","green","navyblue"))(100))
          tl.col = "black", mar=c(0,0,1.5,0))

# PCA
myPr <- prcomp(firms[-Paris, 3:8], scale = TRUE)
summary(myPr)
plot(myPr, type = "l")
biplot(myPr, scale = 0)
#extract PC scores...
str(myPr)
#myPr$x #checking principal component scores
# firms2 <- cbind(firms[-Paris, 3:8], myPr$x[, 1:2])
# head(firms2)
# #plot with ggplot...
# ggplot(firms2, aes(PC1, PC2)) +
#   stat_ellipse(geom = "polygon", col = "black", alpha = 0.5) +
#   geom_point(shape = 21, col = "black")
# # correlations between variables and PCs...
# cor(firms_clean[, 4:8], firms2[,9:10])

# using ggbiplot
ggbiplot(myPr, obs.scale = 1, var.scale = 1, varname.size = 5.5, varname.adjust = 1) +
  ggtitle("Biplot for the firms's size") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Cluster Analysis 

```{r clustering}
# firms_sampled <- firms[1:1000, ] # subsampling
# head(firms_sampled)
# firms_scaled <- scale(firms_sampled[, 3:8]) #scaling the data
# 
# head(firms_scaled)
# 
# firms_truncated <- firms_sampled[, 4:8]
# head(firms_truncated)
# plot(firms_sampled)
# # K-means clustering...
# 
# 
# fitK_scaled <- kmeans(firms_scaled, 4) 
# head(fitK_scaled)
# 
# fitK <- kmeans(firms_truncated, 5)
# head(fitK)
# str(fitK)
# plot(firms_sampled, col = fitK$cluster) #plotting data colored according to cluster membership
# 
# #choosing K---
# k <- list()
# for(i in 1:10){
#   k[[i]] <- kmeans(firms_truncated, i)
# }
# head(k)
# 
# betweenss_totalss <- list()
# for(i in 1:10){
#   betweenss_totalss[[i]] <- k[[i]]$betweenss/k[[i]]$totss
# }
# plot(1:10, betweenss_totalss, type ="b",
#      ylab = "Between SS / Total SS", xlab = "Clusters (k)") #calculating and plotting between SS to total SS ratio against number of clusters
# 
# for(i in 1:5) {
#   plot(firms, col = k[[i]]$cluster) #plotting data based on membership to clusters for k = 1 to 5 clusters
# }
# head(fitM)
# fitM <- Mclust(firms_truncated)
# plot(fitM)
# #Model-based clustering using mclust
# 
# head(clusters)
# plot(firms_sampled, col = clusters) # as we can see, it performs quite similar to the K-means 
# rect.hclust(fitH, k = 5, border = "red") # visualising dendrogam cut at k =5
# clusters <- cutree(fitH, 5)  # vector with cluster membership for each observation
# plot(fitH)
# d <- dist(firms_truncated)
# fitH <- hclust(d, "ward.D2")
# 
# #Hierarchical clustering---
# 

```


## Issues

* Some towns have 100% of null firms


## How to use these data 

We plan to use these for the following tasks:

* predict the salaries using such information as proxy for the competition in the job market;
* predict the total number of firms, using salary data;
* geo-spatial plot for firms' size 
* ... missing: histogram for firms' size


# Analyze geographical data 

## Pre-processing 

Correct typos for longitude data and keep just the unique CODGEO to avoid towns with multiple postal codes:
```{r pre processing geo}

# preliminary checks
dim(geo)
names(geo)
head(geo)
str(geo)
summary(geo)

# spot "," instead of "." in longitude
newLong       <- as.character(geo$longitude)    # copy the vector
sum(grep(",", newLong))                         # total commas
ind_long_err  <- grep(",", newLong)             # indexing them
newLong       <- gsub(",", ".", newLong)        # substituting them with dots
indNA_Long    <- is.na(as.numeric((newLong)))   # spot NA
geo$longitude[indNA_Long]                       # verify that they were actually missing
geo$longitude <- as.numeric(newLong)            # overwrite the longitude variable with the new one

# Check for duplicated data (e.g., cities with different postal codes, that we dropped):
  # ex. to verify it,  try on the initial dataset:
  # sum(geo$nom_commune == "Paris")
  # ind_duplic <- geo$nom_commune == "Paris"
  # geo[ind_duplic,]
sum(duplicated.data.frame(geo)) 
# retaing unique postal cities
geo <- unique(geo, by = "CODGEO")

# check again
head(geo)
summary(geo)

```


Assign latitude and longitude values for missing data (almost 3000):
```{r assign NA}

# index of NAs and their total
indNA_coord = is.na(geo$latitude) | is.na(geo$longitude)
sum(indNA_coord)

# code used to retrieve the NA using Google API, which have been saved in a csv file
# 
# # initialize variables
# city_search = 0
# res = as.data.frame(matrix(c(0, 0, 0), 1, 3))
# names(res) = c("lon", "lat", "address")
# 
# # retrieve lat and long (Google API = 2500 request per day)
# # my_iter = floor(sum(indNA_coord)/3)
# for (i in 1:sum(indNA_coord)){
# 
#   # city searched
#   city_search[i] = paste(c(as.character(NA_coord$town_name[i]), as.character(NA_coord$postal_code[i]), as.character(NA_coord$department[i]), "France"), sep=" ", collapse = ", ")
#   
#   # solution
#   res[i,] = geocode(city_search[i], output = "latlona", source = c("google", "dsk"), messaging = FALSE)
# 
#   # retrieve still missing data, because of existing problems with API (up to 15 trials)
#   j = 0
#   while (any(is.na(res[i,])) & j < 25){
#     res[i,] = geocode(city_search[i], output = "latlona", source = c("google", "dsk"), messaging = FALSE)
#     j = j + 1
#   }
# }

# # check the solution
# sol = cbind(searched = city_search, res)

# # save it as a csv file to save time
# write.csv(retrieved_geo_NA[,2:3], "geo_NA_Final.csv", quote = FALSE, row.names=FALSE, fileEncoding = "UTF-8")
    

# read the created csv
setwd("./data")
retrieved_geo_NA = read.csv("geo_NA_Final.csv", header = T, encoding = "UTF-8")
# get only long and lat and assign to original NA 
geo$latitude[indNA_coord] = retrieved_geo_NA[,2]
geo$longitude[indNA_coord] = retrieved_geo_NA[,1]

# there are 37 still missing units, which are towns located in old colonies far from Europe
indNA_coord = is.na(geo$latitude) | is.na(geo$longitude)
sum(indNA_coord)
# exclude those towns
geo = geo[!indNA_coord,]

summary(geo)

```

## Descriptive statistics 

Plot available towns in a map:

```{r map}

# delete non-European countries
ind_nonEur = geo$latitude < 30 | geo$latitude > 70 |geo$longitude < -20 | geo$longitude > 20
sum(ind_nonEur)
geo = geo[!ind_nonEur,]

# center of France, obtained using:
# fra_center = as.numeric(geocode("France"))
fra_center = c(2.213749, 46.227638)
# plot all European towns available
geo_pos = as.data.frame(cbind(lon = geo$longitude, lat = geo$latitude))
geo_pos = geo_pos[complete.cases(geo_pos),]
ggmap(get_googlemap(center=fra_center, scale=2, zoom=5), extent="normal") +
  geom_point(aes(x=lon, y=lat), data=geo_pos, col="orange", alpha=0.8, size=0.6) 

```



## What we have learned 

Solved: 

* Latitude is missing and not longitude
* There are some duplications
* Exclude non-European


## How to use these data 

* Compare European towns vs. old colonies?
* Useful for all datasets/analyses


# Analyze salary data 

## Pre-processing 

Verification of the dataset:
```{r pre processing salary}

# preliminary checks
dim(salary)
names(salary)
head(salary)
str(salary)
summary(salary)

# Check for duplicated data
sum(duplicated.data.frame(salary))

```



## Descriptive statistics 

Univariate analysis comparing salaries for both genders among various job categories:

```{r boxplots works}

#  number of units
n_sex <- length(salary$sal_Females)
# vector representing males and females
Label <- c(rep("M", n_sex*5), rep("F", n_sex*5))
# vector representing the variable considered
Variable <- c(rep("General", n_sex), 
             rep("Executive", n_sex),
             rep("MidManager", n_sex),
             rep("Employee", n_sex),
             rep("Worker",n_sex),
             rep("General", n_sex), 
             rep("Executive", n_sex),
             rep("MidManager", n_sex),
             rep("Employee", n_sex),
             rep("Worker",n_sex))
# merge these data
sal_sex = cbind.data.frame(Label = Label, 
             value = c(salary$sal_Males, salary$sal_M_executive, salary$sal_M_midManager, salary$sal_M_employee, salary$sal_M_worker,
                       salary$sal_Females, salary$sal_F_executive, salary$sal_F_midManager, salary$sal_F_employee, salary$sal_F_worker),
             Variable = Variable)
# plotting phase
ggplot(data = sal_sex, aes(x=Label, y=value)) +
  geom_boxplot(aes(fill = Label)) +
  # not color points replacing colour = group instead of colour=Label
  geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75)) +
  facet_wrap( ~ Variable, scales="free") +
  xlab("Sex") + ylab("Mean net salary per hour") + ggtitle("Gender comparison for different job positions") +
  theme(plot.title = element_text(hjust = 0.5)) +      stat_boxplot(geom = "errorbar", width = 0.5)
  # + guides(fill=guide_legend(title="Legend"))


# the same but excluding outliers
ggplot(data = sal_sex, aes(x=Label, y=value)) +
  scale_y_continuous(limits = quantile(sal_sex$value, c(0, 0.9))) +
  geom_boxplot(aes(fill = Label)) +
  geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75)) +
  facet_wrap( ~ Variable, scales="free") +
  xlab("Sex") + ylab("Mean net salary per hour") + 
  ggtitle("Gender comparison for different job positions excluding the last decile") +
  theme(plot.title = element_text(hjust = 0.5)) +
  stat_boxplot(geom = "errorbar", width = 0.5)

```


Univariate analysis comparing salaries for both genders among various ages:

```{r boxplots ages}

# vector representing males and females
Label <- c(rep("M", n_sex*3), rep("F", n_sex*3))
# vector representing the variable considered
Variable <- c(rep("18-25", n_sex), 
              rep("26-50", n_sex),
              rep("51+", n_sex),
              rep("18-25", n_sex), 
              rep("26-50", n_sex),
              rep("51+", n_sex))
# merge these data
sal_sex <- cbind.data.frame(Label = Label, 
                           value = c(salary$sal_M_18_25, salary$sal_M_26_50, salary$sal_M_51plus, 
                                     salary$sal_F_18_25, salary$sal_F_26_50, salary$sal_F_51plus),
                           Variable = Variable)
# plotting phase
ggplot(data = sal_sex, aes(x=Label, y=value)) +
  geom_boxplot(aes(fill = Label)) +
  geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75)) +
  facet_wrap( ~ Variable, scales="free") +
  xlab("Sex") + ylab("Mean net salary per hour") + ggtitle("Gender comparison for different ages") +
  theme(plot.title = element_text(hjust = 0.5)) + ylim(c(5, 100)) +
  stat_boxplot(geom = "errorbar", width = 0.5)

```


The income inequality between genders, age groups and working positions is clear.
In the following analyses the focus is on the salary ratio between women and men among different
job positions:
```{r ratio F vs M accross jobs}

# Gender salary ratio and general level of income

# Overall mean salary: The higher the net mean income, the more skewed the ratio of salary between female and male is. Only 2 towns have a ratio>1
# create overall F vs M ratio
salary$salary_ratio_FvsM <- salary$sal_Females / salary$sal_Males
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="Overall salary ratio (females/males)", y="Density") + 
  labs(title = "Overall salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs overall mean salary
ggplot(salary, aes(x= sal_general, y=salary_ratio_FvsM)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="Overall salary ratio(females/males)") + 
  labs(title = "Overall salary ratio between females and males vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm") 


# Executives mean salary: a bit better the situation for females in this case and less skewed
# create Executives F vs M ratio
salary$salary_ratio_FvsM_Exec <- salary$sal_F_executive / salary$sal_M_executive
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM_Exec)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="Executives salary ratio (females/males)", y="Density") + 
  labs(title = "Executives salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs executives mean salary
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_Exec)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="Executives salary ratio (females/males)") + 
  labs(title = "Executives salary ratio between females and males \n vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm")


# Middle managers mean salary: ....
# create Middle managers F vs M ratio
salary$salary_ratio_FvsM_midManag <- salary$sal_F_midManager / salary$sal_M_midManager
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM_Exec)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="Middle managers salary ratio (females/males)", y="Density") + 
  labs(title = "Middle managers salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs executives mean salary
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_midManag)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="Middle managers salary ratio (females/males)") + 
  labs(title = "Middle managers salary ratio between females and males \n vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm")


# Workers mean salary: ...
# create workers F vs M ratio
salary$salary_ratio_FvsM_worker <- salary$sal_F_worker / salary$sal_M_worker
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM_worker)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="Workers salary ratio (females/males)", y="Density") + 
  labs(title = "Workers salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs workers mean salary
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_worker)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="Workers salary ratio (females/males)") + 
  labs(title = "Workers salary ratio between females and males \n vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm")


# Employee mean salary: ...
# create Employee F vs M ratio
salary$salary_ratio_FvsM_employee <- salary$sal_F_employee / salary$sal_M_employee
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM_employee)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="Employee salary ratio (females/males)", y="Density") + 
  labs(title = "Employee salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs Employee mean salary
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_employee)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="Employee salary ratio (females/males)") + 
  labs(title = "Employee salary ratio between females and males \n vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm")

```


Now the focus is on the salary ratio between women and men among different age groups:
```{r ratio F vs M accross ages}

# 18-25 mean salary: are quite equal apart from some outliers and a quadratic trend
# create 18-25 F vs M ratio
salary$salary_ratio_FvsM_18_25 <- salary$sal_F_18_25 / salary$sal_M_18_25
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM_18_25)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="18-25 salary ratio (females/males)", y="Density") + 
  labs(title = "18-25 salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs 18-25 mean salary
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_18_25)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="18-25 salary ratio (females/males)") + 
  labs(title = "18-25 salary ratio between females and males \n vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm")
# scatter plot vs 18-25 mean salary for them
ggplot(salary, aes(x= sal_18_25, y= salary_ratio_FvsM_18_25)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="18-25 salary", y="18-25 salary ratio (females/males)") + 
  labs(title = "18-25 salary ratio between females and males \n vs. overall 18-25 salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "loess")


# 26-50 mean salary: ...
# create 26-50 F vs M ratio
salary$salary_ratio_FvsM_26_50 <- salary$sal_F_26_50 / salary$sal_M_26_50
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM_26_50)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="26-50 salary ratio (females/males)", y="Density") + 
  labs(title = "26-50 salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs 26-50 mean salary
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_26_50)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="26-50 salary ratio (females/males)") + 
  labs(title = "26-50 salary ratio between females and males \n vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm")


# 51+ mean salary: ...
# create 51+ F vs M ratio
salary$salary_ratio_FvsM_51plus <- salary$sal_F_51plus / salary$sal_M_51plus
# histogram
ggplot(data=salary, aes(salary$salary_ratio_FvsM_51plus)) + 
  geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 50) + 
  geom_density(col="black") + 
  labs(x="51+ salary ratio (females/males)", y="Density") + 
  labs(title = "51+ salary ratio between females and males") + 
  theme(plot.title = element_text(hjust = 0.5)) 
# scatter plot vs 26-50 mean salary
ggplot(salary, aes(x= sal_general, y= salary_ratio_FvsM_51plus)) +  
  geom_point(size = 0.5, colour = "#0091ff")+ 
  labs(x="Overall salary", y="51+ salary ratio (females/males)") + 
  labs(title = "51+ salary ratio between females and males \n vs. overall salary") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_smooth(method = "lm")

```


Highlight bivariate relations:
```{r bivariate plots}

# correlation matrix
corrplot(cor(salary[, 3:ncol(salary)]), method = "circle", title = "Correlation matrix for salary data", 
         diag = T, tl.cex=0.5, type="lower", 
         tl.col = "black", mar=c(0,0,1.5,0)) 

# most general pairs
pairs(salary[c(3:8, 13, 18:20)], gap=0, main = "Scatter matrix of the main variables in salary data", cex = 0.6)
# pairs highlighting genders' differences
pairs(salary[c(9:12, 14:17)], gap=0, main = "Scatter matrix of job categories for both genders", cex = 0.6)

```



## Linear models

First we perform some easy task
fitting a regression model to predict the salaries of people in age 26-50 using as regressor 51+ years:

```{r exLinMod, fig.keep='all'}
# # fit and show OLS estimate
# plot(salary$sal_26_50 ~ salary$sal_51plus)
# fit_LM_26_50 = lm(salary$sal_26_50 ~ salary$sal_51plus, data = salary) 
# abline(fit_LM_26_50, lwd=3, col="red")
# # diagnostics
# summary(fit_LM_26_50)
# plot(fit_LM_26_50)
# 
# # Same as before but adding polynomials which are evauated using 10-folds cross validation
# set.seed(1)
# # k-Fold Cross-Validation
# cv.err.K = rep(0, 5)
# cv.err.K = rbind(cv.err.K, cv.err.K)
# for (i in 1:5){
#   fit_LM_26_50.K = glm(sal_26_50 ~ poly(sal_51plus, i), data = salary)
#   cv.err.K[,i] = cv.glm(salary, fit_LM_26_50.K, K = 10)$delta[1]
# }
# # plotting results
# plot(cv.err.K[1,], type = 'l', col = 'red', xlab = "Polynomials' order", 
#      ylab = "10-folds CV", main = "CV and adjusted CV for different polynomials")
# lines(cv.err.K[2,], col = 'green')
# points(which.min(cv.err.K), cv.err.K[1, which.min(cv.err.K)], col = "red", cex=2, pch=20)
# legend('topright', legend = c('CV', 'Adj. CV'), col = c('red', 'green'), pch = 10)

```


Predicting salary for young people using Elastic NEt with CV and 10-folds CV. The predictors are most of the original variables and their 2nd, 3rd order polynomials and log tranformation:

```{r}
# # funtion to plot BSS
# plot.regsubsets2 <-  
#   function (x, labels = obj$xnames, main = NULL, scale = c("bic",  
#                                                            "Cp", "adjr2", "r2"), col = gray(seq(0, 0.9, length = 10)), ...)  
#   { 
#     obj <- x 
#     lsum <- summary(obj) 
#     par(mar = c(7, 5, 6, 3) + 0.1) 
#     nmodels <- length(lsum$rsq) 
#     np <- obj$np 
#     propscale <- FALSE 
#     sscale <- pmatch(scale[1], c("bic", "Cp", "adjr2", "r2"),  
#                      nomatch = 0) 
#     if (sscale == 0)  
#       stop(paste("Unrecognised scale=", scale)) 
#     if (propscale)  
#       stop(paste("Proportional scaling only for probabilities")) 
#     yscale <- switch(sscale, lsum$bic, lsum$cp, lsum$adjr2, lsum$rsq) 
#     up <- switch(sscale, -1, -1, 1, 1) 
#     index <- order(yscale * up) 
#     colorscale <- switch(sscale, yscale, yscale, -log(pmax(yscale,  
#                                                            1e-04)), -log(pmax(yscale, 1e-04))) 
#     image(z = t(ifelse(lsum$which[index, ], colorscale[index],  
#                        NA + max(colorscale) * 1.5)), xaxt = "n", yaxt = "n",  
#           x = (1:np), y = 1:nmodels, xlab = "", ylab = scale[1],  
#           col = col) 
#     laspar <- par("las") 
#     on.exit(par(las = laspar)) 
#     par(las = 2) 
#     axis(1, at = 1:np, labels = labels, ...) # I modified this line 
#     axis(2, at = 1:nmodels, labels = signif(yscale[index], 2)) 
#     if (!is.null(main))  
#       title(main = main) 
#     box() 
#     invisible(NULL) 
#   } 
# 
# set.seed(2018)
# 
# # load the data
# ind = salary$sal_18_25 < 11.5
# y = salary$sal_18_25[ind]
# x = cbind.data.frame(salary$sal_26_50, salary$sal_51plus, 
#                      salary$sal_general,  salary$sal_executive, salary$sal_midManager, 
#                      salary$sal_employee, salary$sal_worker, 
#                      salary$sal_Males, salary$sal_Females)
# x = x[ind, ]
# yx = cbind.data.frame(y, x)
# 
# # original response variable histogram
# ggplot(data=salary, aes(salary$sal_18_25)) + 
#   geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 35) + 
#   geom_density(col="black") + 
#   labs(x="salary^-1", y="Density") + 
#   ggtitle("Original response variable") + 
#   theme(plot.title = element_text(hjust = 0.5)) 
# 
# # response variable histogram (excluding outliers)
# ggplot(data=salary[ind,], aes(y)) + 
#   geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 35) + 
#   geom_density(col="black") + 
#   labs(x="salary^-1", y="Density") + 
#   ggtitle("Original response variable excluding outliers") + 
#   theme(plot.title = element_text(hjust = 0.5)) 
# 
# # after sampling to avoid serial correlation
# indd = sample(1:length(y), round(length(y)*0.4))
# yx = yx[indd,]
# ggplot(data=salary[ind,][indd,], aes(y[indd])) + 
#   geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 30) + 
#   geom_density(col="black") + 
#   labs(x="salary^-1", y="Density") + 
#   ggtitle("Sampled response variable and excluding outliers") + 
#   theme(plot.title = element_text(hjust = 0.5)) 
# 
# # correlations
# # corrplot(cor(yx), method = "number", title = "Correlation matrix for salary",
# #          diag = T, tl.cex=0.5, type="lower", #col = colorRampPalette(c("red","green","navyblue"))(100))
# #          tl.col = "black")  # , mar=c(0,0,1.5,0)
# 
# # scatter matrix
# # pairs(yx, gap=0, main = "Scatter matrix for some variables in salary")
# # manually remove outliers in mid mangager
# summary(yx)
# inddd = yx$`salary$sal_midManager` < 20
# yx = yx[inddd,]
# # final dataset
# pairs(yx, gap=0, main = "Scatter matrix for the variables in the model")
# 
# # create final dataframe
# require(leaps) 
# # assign names for predictors transformation
# namesdataBS = names(yx)
# yx = cbind.data.frame(yx, yx[,2:ncol(yx)]^2, yx[,2:ncol(yx)]^3, log(yx[,2:ncol(yx)]))
# dim(yx)
# lll = ((dim(yx)[2]-1)/4) 
# for (i in 1:lll+1){ 
#   str = namesdataBS[i] 
#   namesdataBS[i] = regmatches(str, regexpr("_", str), invert = TRUE)[[1]][-1] 
# } 
# namesdataBS[(lll+2):(lll*2+1)] = paste(namesdataBS[1:lll+1], rep("^2", lll)) 
# namesdataBS[(lll*2+2):(lll*3+1)] = paste(namesdataBS[1:lll+1], rep("^3", lll)) 
# namesdataBS[(lll*3+2):(lll*4+1)] = paste(namesdataBS[1:lll+1], rep("log", lll)) 
# names(yx) = namesdataBS 
# 
# # Elastic net
# x = as.matrix(yx[, 2:ncol(yx)])
# y = yx[, 1]
# par(mfrow =c(3,2))
# for (j in c(0, 0.2, 0.4, 0.6, 0.8, 1)){
#   # set.seed (3)
#   cv.out = cv.glmnet(x, y, alpha = j)
#   plot(cv.out)
#   title(paste("alpha = ", j), line = 2.3)
# }
# mtext(expression("Best lambda for salary 18-25 using elastic and 10-folds CV"), outer=TRUE,  cex=1, line=-1.4) 
# 
# 
# # split the date leaving the 20% for CV
# par(mfrow =c(1,1))
# train = sample(1:nrow(x), floor(nrow(x)*0.8))
# test = -train
# y.test = y[test]
# x = as.matrix(x)
# itercol = 1
# for (j in c(0, 0.2, 0.4, 0.6, 0.8, 1)){
#   # set.seed (3)
#   lasso.mod = glmnet(x[train,], y[train], alpha = j, thresh = 1e-10)
#   err.i = rep("NA", length(lasso.mod$lambda))
#   for (i in 1:length(lasso.mod$lambda)){
#     lasso.pred = predict(lasso.mod, s = lasso.mod$lambda[i], newx = x[test,], alpha = j)
#     err.i[i] = mean((lasso.pred - y.test)^2)
#   }
#   if (itercol == 1){
#     plot(log(lasso.mod$lambda), err.i, xlab = 'log Lambda', ylab = 'test set MSE', 
#          main = 'Test MSE among different Lambdas', type = "b", col = itercol)
#   } else{
#     lines(log(lasso.mod$lambda), err.i, type = "b", col = itercol)
#   }
#   bestlam = which.min(err.i)
#   points(log(lasso.mod$lambda)[bestlam], err.i[bestlam], col = 3, cex=2, pch=20)
#   itercol = itercol +1
# }
# 
# 
# # best subset selection
# best.sub = regsubsets(y ~ ., data = yx, nvmax = ncol(yx)) 
# best.sub.summary = summary(best.sub) 
# # manual plotting 
# par(mfrow =c(2,2))
# # rsq 
# plot(best.sub.summary$rsq , xlab="Number of Variables", ylab="Rsq", type="l") 
# ind_Rsq = which.max(best.sub.summary$rsq) 
# points(ind_Rsq, best.sub.summary$adjr2[ind_Rsq], col ="red", cex=2, pch=20) 
# # adjRsq 
# plot(best.sub.summary$adjr2 ,xlab="Number of Variables", ylab="Adjusted RSq", type="l") 
# ind_adjRsq = which.max(best.sub.summary$adjr2) 
# points(ind_adjRsq, best.sub.summary$adjr2[ind_adjRsq], col ="red", cex=2, pch=20) 
# # Cp 
# plot(best.sub.summary$cp ,xlab="Number of Variables", ylab="Cp", type="l") 
# ind_Cp = which.min(best.sub.summary$cp) 
# points(ind_Cp, best.sub.summary$cp[ind_adjRsq], col ="red", cex=2, pch=20) 
# # bic 
# plot(best.sub.summary$bic ,xlab="Number of Variables", ylab="bic", type="l") 
# ind_bic = which.min(best.sub.summary$bic) 
# points(ind_bic, best.sub.summary$bic[ind_bic], col ="red", cex=2, pch=20) 
# # mtext("My 'Title' in a strange place", line=15) 
# mtext("Best subset selection for salary 18-25", outer=TRUE,  cex=1.2, line=-2.5) 
# # built-in plots 
# par(mfrow=c(1,1)) 
# plot(best.sub, scale = "r2") 
# plot(best.sub, scale = "adjr2") 
# plot(best.sub, scale = "Cp") 
# plot(best.sub, scale = "bic") 
# plot.regsubsets2(best.sub, scale = "bic", cex.axis = 0.9) 
# mtext("Best subset selection for salary 18-25 using BIC", outer=TRUE,  cex=1.4, line=-3.5) 
# # retrieve the model with min BIC 
# coefficients(best.sub, which.min(best.sub.summary$bic))
# names(coefficients(best.sub, 10))
# # nnn = names(coefficients(best.sub, which.min(best.sub.summary$bic)))
# 


```



ANOVA model for salary:
```{r}
# 
# # create response variable
# sal_y = c(salary$sal_M_18_25, salary$sal_M_26_50, salary$sal_M_51plus,
#           salary$sal_M_executive, salary$sal_M_midManager, salary$sal_M_employee, salary$sal_M_worker,
#           salary$sal_F_18_25, salary$sal_F_26_50, salary$sal_F_51plus,
#           salary$sal_F_executive, salary$sal_F_midManager, salary$sal_F_employee, salary$sal_F_worker)
# 
# n_sal_y = length(sal_y)             # length response variable
# n_cat = length(salary$sal_M_18_25)  # length of each category (i.e., original vectors)
# 
# # create sex dummy variable, 1 for males and 0 for females
# sal_sex = rep(0, n_sal_y)   # full regressors
# sal_sex[1:n_sal_y/2] = 1    # assign males
# 
# # create age dummy variables, 18-25 years old is the base case
# sal_age = cbind(rep(0, n_sal_y), rep(0, n_sal_y)) # full regressors
# # 26-50 y.o.
# sal_age[(n_cat+1):(n_cat*2), 1] = 1     # males
# sal_age[(n_cat*8+1):(n_cat*9), 1] = 1   # females
# # 51+ y.o.
# sal_age[(n_cat*2+1):(n_cat*3), 2] = 1   # males
# sal_age[(n_cat*9+1):(n_cat*10), 2] = 1  # females
# 
# # create job type dummy variables, worker is the base case
# sal_job = cbind(rep(0, n_sal_y), rep(0, n_sal_y), rep(0, n_sal_y)) # full regressors
# # executives
# sal_job[(n_cat*3+1):(n_cat*4), 1] = 1     # males
# sal_job[(n_cat*10+1):(n_cat*11), 1] = 1   # females
# # middle managers
# sal_job[(n_cat*4+1):(n_cat*5), 2] = 1     # males
# sal_job[(n_cat*11+1):(n_cat*12), 2] = 1   # females
# # employee
# sal_job[(n_cat*5+1):(n_cat*6), 3] =   1   # males
# sal_job[(n_cat*12+1):(n_cat*13), 3] = 1   # females
# 
# # final data set 
# data_ANOVA = cbind.data.frame(response = sal_y, sex = sal_sex, age = sal_age, job = sal_job)
# names(data_ANOVA)
# # show regressors' shape
# imagemat(data_ANOVA[,-1], xaxt = "n", main = "Factors for ANOVA")  
# axis(1, at=1:6, labels=c("Sex", "Age 26-50", "Age 51+", "Execut.", "Mid.Man.", "Empl.")) 
# box()
# # sub sample to avoid correlation
# set.seed(20)
# subs = sample(1:n_sal_y, size = round(n_sal_y*0.2))
# data_ANOVA = data_ANOVA[subs,]
# # show randomized data
# imagemat(data_ANOVA[,-1], xaxt = "n", main = "Factors for ANOVA")  
# axis(1, at=1:6, labels=c("Sex", "Age 26-50", "Age 51+", "Execut.", "Mid.Man.", "Empl.")) 
# box()
# 
# # plot response variable
# hist(data_ANOVA[,1], 30)
# hist(log(data_ANOVA[,1]), 30)
# hist(sqrt(data_ANOVA[,1]), 30)
# hist(data_ANOVA[,1]^-1, 30)
# sal_y = data_ANOVA[,1]^-1  # also suggested by Box-Cox transformation
# ggplot(data=data.frame(data_ANOVA[,1]), aes(sal_y)) + 
#   geom_histogram(aes(y =..density..), col="black", fill="blue", alpha = .3, bins = 40) + 
#   geom_density(col="black") + 
#   labs(x="salary^-1", y="Density") + 
#   ggtitle("Transformation of salary found using Box-Cox transformation") + 
#   theme(plot.title = element_text(hjust = 0.5)) 
# 
# sex = sal_sex[subs]
# age = sal_age[subs,]
# job = sal_job[subs,]
# # ANOVA model
# sal_ANOVA = lm(sal_y ~ sex + age + job + sex:age + sex:job)
# # names(sal_ANOVA$coefficients) = c("Males", "26-50", )
# summary(sal_ANOVA)
# anova((sal_ANOVA))
# 
# # box-cox transformation suggested to use y^-1
# boxcox(sal_ANOVA)
# title("Box-Cox transformation of the response")
# 
# # BSS
# best.sub = regsubsets((sal_y ~ sex + age + job + sex:age + sex:job), 
#                       data = data_ANOVA, nvmax = 12) 
# best.sub.summary = summary(best.sub) 
# # plots: manual plotting 
# par(mfrow =c(2,2)) 
# # rsq 
# plot(best.sub.summary$rsq , xlab="Number of Variables", ylab="Rsq", type="l") 
# ind_Rsq = which.max(best.sub.summary$rsq) 
# points(ind_Rsq, best.sub.summary$adjr2[ind_Rsq], col ="red", cex=2, pch=20) 
# # adjRsq 
# plot(best.sub.summary$adjr2 ,xlab="Number of Variables", ylab="Adjusted RSq", type="l") 
# ind_adjRsq = which.max(best.sub.summary$adjr2) 
# points(ind_adjRsq, best.sub.summary$adjr2[ind_adjRsq], col ="red", cex=2, pch=20) 
# # Cp 
# plot(best.sub.summary$cp ,xlab="Number of Variables", ylab="Cp", type="l") 
# ind_Cp = which.min(best.sub.summary$cp) 
# points(ind_Cp, best.sub.summary$cp[ind_adjRsq], col ="red", cex=2, pch=20) 
# # bic 
# plot(best.sub.summary$bic ,xlab="Number of Variables", ylab="bic", type="l") 
# ind_bic = which.min(best.sub.summary$bic) 
# points(ind_bic, best.sub.summary$bic[ind_bic], col ="red", cex=2, pch=20) 
# # mtext("My 'Title' in a strange place", line=15) 
# mtext("Best subset selection for ANOVA", outer=TRUE,  cex=1.2, line=-2.5) 
# # existing plots
# par(mfrow=c(1,1)) 
# plot(best.sub, scale = "r2") 
# plot(best.sub, scale = "bic") 
# plot.regsubsets2(best.sub, scale = "bic", cex.axis = 0.7) 
# mtext("Best subset selection for ANOVA", outer=TRUE,  cex=1.2, line=-3.5) 
# plot(best.sub, scale = "Cp") 
# plot(best.sub, scale = "adjr2") 
# # retrieve the model with min BIC 
# coefficients(best.sub, which.min(best.sub.summary$bic))
# 
# 
# # group lasso
# # install.packages("gglasso")
# library(gglasso)
# # install.packages("RColorBrewer")
# library(RColorBrewer)
# # install.packages("zoo")
# library(zoo)
# grp = c(1,2,2,3,3,3,4,4,5,5,5)
# form <- model.matrix(sal_y ~ (sex + age + job)^2)
# head(form)
# form = form[,2:12]
# fit = gglasso(x=form,y=sal_y,group=grp,loss='ls')
# coef.mat=fit$beta
# 
# #Group1 enters the equation
# g1=max(which(coef.mat[1,]==0))
# #Group2 enters the equation
# g2=max(which(coef.mat[2,]==0))
# #Group3 enters the equation
# g3=max(which(coef.mat[4,]==0))
# #Group4 enters the equation
# g4=max(which(coef.mat[7,]==0))
# #Group5 enters the equation
# g5=max(which(coef.mat[9,]==0))
# #Coefficient Plot
# cols=brewer.pal(5,name="Set1")
# plot(fit$b0,main="Coefficient vs Step",
#      ylab="Intercept",xlab="Step (decreasing Lambda)",
#      col=cols[1],
#      xlim=c(-1,100),
#      ylim=c(0.076,max(fit$b0)+0.001),
#      type="l",lwd=4)
# grid()
# par(new=T)
# xx=c(g1,g2,g3,g4,g5)
# yy=c(fit$b0[g1],fit$b0[g2],fit$b0[g3],fit$b0[g4],fit$b0[g5])
# plot(x=xx,y=yy,pch=13,lwd=2,cex=2,col=cols[-1],
#      xlim=c(-1,100),ylim=c(0.076,max(fit$b0)+0.001),
#      xaxt='n',yaxt='n',xlab="",ylab="")
# lmda=round(fit$lambda[c(g1,g2,g3,g4,g5)],4)
# text(x=xx-0.005,y=yy+0.0001,labels=c("Group1","Group2","Group3","Group4","Group5","Group6"),pos=3,cex=0.7)
# text(x=xx-0.005,y=yy-0.0001,labels=paste("Lambda\n=",lmda),pos=1,cex=0.6)
# 
# # coefficient plot 2 (my version)
# cols=brewer.pal(5,name="Set1")
# plot(fit$beta[1,], main="Coefficients vs Lambda",
#      ylab="Coefficients",xlab="Step (decreasing Lambda)",
#      col=cols[1],
#      # xlim=c(-1,100),
#      ylim=c(min(fit$beta), max(fit$beta)),
#      type="l",lwd=4)
# for (j in 2:11){
#   lines(fit$beta[j,],
#         type="l",lwd=4, col=cols[j])
# }
# # plot legend once
# grid()
# par(new=T)
# legend('bottomleft', legend = paste("group ", 1:5), lty=1, col=cols[1:5], cex = 0.7,lwd=2)
# 
# #Cross Validation
# fit.cv=cv.gglasso(x=form,y=sal_y,group=grp,nfolds=10)
# plot(fit.cv, main="10-folds CV for groupwise Lasso in ANOVA")
# #Pick the best Lambda
# lmbda=fit.cv$lambda.1se
# (coefs=coef.gglasso(object=fit,s=lmbda))
# #At best lambda get coefficients and fitted values
# plt=sal_y-predict.gglasso(object=fit,newx=form,s=lmbda,type='link')
# plot(plt, ylab="residuals", xlab="index", main="Plot of residuals")
# abline(0, 0, col= "red")
# # matplot(plt,main="Predicted vs Actual",type='l',lwd=2,col=cols[c(1,2)]),
# #         ylab="Unemplyoment %",
# #         xlab="Time")
# grid()
# 


```


PCA for salary:
```{r}

myPr <- prcomp(salary[, 3:26], scale = TRUE)
myPr
summary(myPr)
plot(myPr, type = "l")
biplot(myPr, scale = 0, cex = 0.5)
str(myPr)
#myPr$x #checking principal component scores
salary2 <- cbind(salary, myPr$x[, 1:2])
head(salary2)
#plot with ggplot...
#require(ggplot2)
ggplot(salary2, aes(PC1, PC2)) + 
  stat_ellipse(geom = "polygon", col = "black", alpha = 0.5) + 
  geom_point(shape = 21, col = "black")
# correlations between variables and PCs...
cor(salary[, 3:26], salary2[,27:28])

ggbiplot(myPr, obs.scale = 1, var.scale = 1, varname.size = 1, varname.adjust = 1) + 
  ggtitle("Biplot for the firms's size") + 
  theme(plot.title = element_text(hjust = 0.5)) 
  
```


## What we have learned 

* Check the outlier in sal_18_25: which city is it, etc.
* evaluate possible multicollinearity
* Try a regression with all predictors ans lasso

## How to use these data 

* ...


# Produce consistent datasets

The CODGEO variables (code_insee in the original geo data) have to be merged.
However, for different reasons already identified by other kaggle users they need some pre-processing.
To do so, some already known mistakes are corrected:

```{r fix CODGEO}

firms$CODGEO      <- sub("A", "0", firms$CODGEO)
firms$CODGEO      <- sub("B", "0", firms$CODGEO)
salary$CODGEO     <- sub("A", "0", salary$CODGEO)
salary$CODGEO     <- sub("B", "0", salary$CODGEO)
population$CODGEO <- sub("A", "0", population$CODGEO)
population$CODGEO <- sub("B", "0", population$CODGEO)
geo$CODGEO        <- sub("A", "0", geo$CODGEO)
geo$CODGEO        <- sub("B", "0", geo$CODGEO)

```


Then all CODGEO are trasformed to integers and four new datasets are created retaining only the common CODGEO:
```{r match CODGEO}

# use only integer values
geo$CODGEO = as.integer(geo$CODGEO)  
population$CODGEO = as.integer(population$CODGEO)
firms$CODGEO = as.integer(firms$CODGEO)
salary$CODGEO = as.integer(salary$CODGEO)

# store datasets' names to loop on them
dataset = c("population", "salary", "firms", "geo")

# obtain sommon IDs for all datasets
for (i in dataset){
  # get i-th name and create a new variable concateneting "NEW" at the end
  nam <- paste(i, "NEW", sep = "")
  # initialize counter to identify the number of iteration in j
  iter = 1
  for (j in dataset){
    if (j != i){
      # for each dataset different from the i-th
      if (iter == 1){
        # 1st iteration: use the original dataset (e.g., geo)
        assign(nam, semi_join(get(i), get(j), by = "CODGEO"))
      } else{
        # successive iteration: use the new dataset (e.g., geoNEW)
        assign(nam, semi_join(get(nam), get(j), by = "CODGEO"))
      }
      iter = iter + 1
    }
  }
}

# check how many observation have been deleted
for (i in dataset){
  del_rows = nrow(get(i)) - nrow(get(paste(i, "NEW", sep = "")))
  del_prop = del_rows / nrow(get(i))
  del_obs = paste("For", i, del_rows, "units have been deleted.",
                  "They were the", round(del_prop*100, digits=2), "% of the total.", sep = " ")
  print(paste(del_obs))
}

print(paste("The new dataset has", nrow(salaryNEW), "units and", 
      ncol(salaryNEW)+ncol(populationNEW)+ncol(firmsNEW)+ncol(geoNEW), "features."))
```

## Pre-processing population data before merging
```{r Pre-processing-Population data before merging}
# preliminary checks
names(population)
summary(population)

# Drop unnecessary columns (NIVGEO is the same for all)
population <- subset(population, select = -c(NIVGEO, LIBGEO))

# converting CODGEO to numeric
population$CODGEO <- as.numeric(as.character(population$CODGEO))


# Refactor sex and MOCO
population$MOCO <- factor(population$MOCO, levels = c(11,12,21,22,23,31,32),
                          labels = c("children_living_with_two_parents", "children living with one parent",
                                     "adults_living_in_couple_without_child", "adults_living_in_couple_with_children",
                                     "adults_living_alone_with_children","persons not from family living in the home",
                                     "persons_living_alone"))
population$sex <- factor(population$sex, levels = c(1,2), labels = c("Male", "Female"))
head(population)
# Take out rows with NB (number of people in this category) equal to 0
# population <- population[population$peopleCategNum != 0,]

head(population)
summary(population)

```

```{r Create cleaned population dataset by CODGEO before merging other dataset}
pop_by_codgeo <- ddply(population, .(CODGEO), function(population) {
  data.frame(total_population = sum(population$peopleCategNum),
             male = sum(population[population$sex == "Male",]$peopleCategNum),
             female = sum(population[population$sex == "Female",]$peopleCategNum),
             child = sum(population[population$ageCateg5 %in% seq(0, 10, by=5),]$peopleCategNum),
             elderly = sum(population[population$ageCateg5 %in% seq(65, 80, by=5),]$peopleCategNum),
             workforce = sum(population[population$ageCateg5 %in% seq(15, 60, by=5),]$peopleCategNum) 
  )})

pop_by_codgeo$dependent <- pop_by_codgeo$child + pop_by_codgeo$elderly
pop_by_codgeo$sex_ratio <- ifelse(pop_by_codgeo$female==0, 0, pop_by_codgeo$male / pop_by_codgeo$female)
pop_by_codgeo$dependency_ratio <- ifelse(pop_by_codgeo$workforce==0, 0, pop_by_codgeo$dependent / pop_by_codgeo$workforce)
pop_by_codgeo$aged_dependency_ratio <- ifelse(pop_by_codgeo$workforce==0, 0, pop_by_codgeo$elderly / pop_by_codgeo$workforce)
pop_by_codgeo$child_dependency_ratio <- ifelse(pop_by_codgeo$workforce==0, 0, pop_by_codgeo$child / pop_by_codgeo$workforce)
```


## merge the data:
```{r Merge the data and create csv file}
# merging
population$CODGEO = as.integer(population$CODGEO)
newDat = merge(firmsNEW, pop_by_codgeo, by="CODGEO")
names(newDat)
head(newDat)
newDat = merge(newDat, salaryNEW, by="CODGEO")
names(newDat)
head(newDat)
newDat = merge(newDat, geoNEW, by="CODGEO")
names(newDat)
head(newDat)
newDat = subset(newDat, select = -town.y)

# NewDat CSV file created
# write.csv(newDat[,2:ncol(newDat)], "newDat.csv", quote = FALSE, row.names=FALSE, fileEncoding = "UTF-8")
```

# Analyze population data 

## Pre-processing 

```{r Pre-processing}
#Pre-processing phase is completed before merging the dataset
```


## Descriptive statistics 

```{r Descriptive statistics}
# #Compare age categories:
# #library(ggplot2)
# #  number of units
# n_cat <- length(population$CODGEO)
# # extract unique categories
# uniq_cat <- unique(population$ageCateg5!=5)
# # vector representing sex for each category
# Label <- c(rep(c('Male', 'Female'), n_cat))
# # vector representing the variable considered
# Variable <- rep(uniq_cat, n_cat/length(uniq_cat))
# Value=population$peopleCategNum
# merge these data
#pop_categ = cbind.data.frame(Label = Label, 
#             value = Value,
#             Variable = Variable)
#p <- ggplot(data = pop_categ, aes(x=Label, y=value)) 
#p <- p + geom_boxplot(aes(fill = Label))
# if you want color for points replace group with colour=Label
#p <- p + geom_point(aes(y=value, colour=Label), position = position_dodge(width=0.75))
#p <- p + facet_wrap( ~ Variable, scales="free")
#p <- p + xlab("x-axis") + ylab("y-axis") + ggtitle("Category comparison")
# p <- p + guides(fill=guide_legend(title="Legend"))
#p
```


```{r Restructuring population data}
# Restructure population data to produce the demographic profile per town
# install.packages("plyr")
library(plyr)
population=populationNEW
summary(pop_by_codgeo)
```

```{r Scaling population data to log}
# Scale population to log
pop_by_codgeo$total_population_log <- log10(pop_by_codgeo$total_population)

# Histogram of total population per town
hist(pop_by_codgeo$total_population, ylim=c(0,40000), breaks = seq(0, 2500000, by=250000), xlab="", main = "", labels=T, col ="light blue")

hist(pop_by_codgeo$total_population_log, xlab="Total Population in log", main = "Total population per CODGEO", col ="light blue")

hist(pop_by_codgeo$dependency_ratio, xlab="", main = "dependency ratio", col ="light blue")
hist(pop_by_codgeo$sex_ratio, xlab="", main = "sex ratio", col ="light blue")
```


```{r Merge geography and population data}
# # Merge geo and pop
geo_pop_by_codgeo <- merge(geoNEW, pop_by_codgeo)
summary(geo_pop_by_codgeo)
```

```{r Plot distribution of population for each CODGEO}
# Plot "Distribution of Population for each CODGEO"
#myPalette(low = "white", high = c("green", "red"), mid=NULL, k =50)-Need "GLAD" package
sc <- scale_colour_gradientn(colours =palette(rainbow(6)), limits=c(min(geo_pop_by_codgeo$total_population_log), max(geo_pop_by_codgeo$total_population_log)))
population_distribution <-
  FraMap +
  geom_point(aes(x=geo_pop_by_codgeo$longitude, y=geo_pop_by_codgeo$latitude, colour=geo_pop_by_codgeo$total_population_log),
             data=geo_pop_by_codgeo, alpha=0.8, size=0.6) +
  sc +
  labs(color='Total Population in Log') +
  ggtitle("Distribution of Population for each CODGEO")
population_distribution
```

```{r Plot distribution of aged dependency ratio}
# Plot "Distribution of aged dependency ratio for each CODGEO"
#myPalette(low = "white", high = c("green", "red"), mid=NULL, k =50)-Need "GLAD" package
sc <- scale_colour_gradientn(colours =palette(rainbow(6)), limits=c(min(geo_pop_by_codgeo$aged_dependency_ratio), max(geo_pop_by_codgeo$aged_dependency_ratio)))
aged_ratio_distribution <-
  FraMap +
  geom_point(aes(x=geo_pop_by_codgeo$longitude, y=geo_pop_by_codgeo$latitude, colour=geo_pop_by_codgeo$aged_dependency_ratio),
             data=geo_pop_by_codgeo, alpha=0.8, size=0.6) +
  sc +
  labs(color='') +
  ggtitle("Aged dependency ratio per CODGEO")
aged_ratio_distribution
```



```{r Population pyramide}
# Population pyramide
population_data2 <- ddply(population, .(sex, ageCateg5), function(population) {
  data.frame(total_population = sum(population$peopleCategNum))
  })
pop_pyramid <- ggplot(data = population_data2, 
       mapping = aes(x = ageCateg5, fill = sex, 
                     y = ifelse(test = sex == "Male", 
                                yes = -total_population, no = total_population))) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = abs, limits = max(population_data2$total_population) * c(-1,1)) + ggtitle("Pyramid of Population") + theme(plot.title = element_text(hjust = 0.5)) + labs(x= "Age")+ labs(y = "Population") + coord_flip()
print(pop_pyramid)
```



## Unsupervised learning 
```{r PCA population-Create clean dataset}
# PCA trial 
# create a clean dataset with only necessary variables inside.
pca_pop_town <- ddply(pop_by_codgeo, .(CODGEO), function(pop_by_codgeo) {
  data.frame(pop_by_codgeo$sex_ratio, pop_by_codgeo$dependency_ratio, pop_by_codgeo$aged_dependency_ratio, pop_by_codgeo$child_dependency_ratio)})

# rename the variables 
names(pca_pop_town)[1:ncol(pca_pop_town)] <-
  c("CODGEO",
    "sex_ratio",
    "dependency_ratio",
    "aged_dep_ratio",
    "child_dep_ratio")

summary(pca_pop_town)
```


```{r PCA population }
# PCA population
set.seed(3)
subs = sample(1:nrow(pca_pop_town), size = round(nrow(pca_pop_town)*0.2))
summary(pca_pop_town)

pcapop <- prcomp(pca_pop_town[subs, 2:5])
# pcapop$rotation

plot(pcapop, type = "l")
biplot(pcapop, scale = 0, cex = 0.5)
# fviz_pca_ind(pcapop) + labs(title="PCA", x="PC1", y="PC2")
# scale_color_gradient2(low="blue", mid="white",high="red", midpoint=4)
# fviz_pca_ind(pcapop, col.ind="contrib") + scale_color_gradient2(low="blue", mid="white", high="red", midpoint=4) + theme_minimal()
str(pcapop)

ggbiplot(pcapop, obs.scale = 1, var.scale = 1, varname.size = 4.5, varname.adjust = 1) +
  ggtitle("Biplot for dependency ratios") + 
  theme(plot.title = element_text(hjust = 0.5))

#pcapop$x #checking principal component scores
pca_pop_town2 <- cbind(pca_pop_town[subs,], pcapop$x[, 1:2])
# head(pca_pop_town2)
```

```{r Plot PCA}
#plot with ggplot...
ggplot(pca_pop_town2, aes(PC1, PC2)) +
    stat_ellipse(geom = "polygon", col = "gray", alpha = 0.5) +
    geom_point(shape = 21, col = "black")
```

```{r Proportion of variance explained & cumulative PVE}
# Proportion of variance explained & cumulative PVE
pcapop$sdev
pr.var=pcapop$sdev^2 
pve=pr.var/sum(pr.var)
pve

plot(pve, xlab="PCA", ylab="PVE", ylim=c(0,1), type='b')
plot(cumsum(pve), xlab="PCA", ylab="Cumulative PVE", ylim=c(0,1), type='b')
```

```{r Kmean}
# kmean trial
km.out=kmeans(pca_pop_town[subs,2:5], 5, nstart=50)
plot(pca_pop_town[subs,2:5], col=(km.out$cluster), pch=20, cex=1)
```

```{r H-cluster}
#hierarchical clustering
sd.data=scale(pca_pop_town)
par(mfrow=c(1,3))
data.dist=dist(sd.data)
plot(hclust(data.dist), labels=pca_pop_town$CODGEO, main="complete", xlab="", sub="", ylab="")

# hc_pop=hclust(dist(pca_pop_town), method="complete")
# plot(hc_pop, labels=pca_pop_town$CODGEO, main="Complete Linkage", xlab="", ylab="", sub="", cex =.9)
```


# Analysis 

General:
```{r Correlation plot with new merged data}
corrplot(cor(newDat[, 3:20]), method = "circle", title = "Correlation matrix for firms", 
         diag = F, tl.cex=1, #col = colorRampPalette(c("red","green","navyblue"))(100))
         tl.col = "black", type = "lower", mar=c(0,0,1.5,0))
corrplot(cor(newDat[, 21:41]), method = "circle", title = "Correlation matrix for firms", 
         diag = F, tl.cex=1, type = "lower", #col = colorRampPalette(c("red","green","navyblue"))(100))
         tl.col = "black", mar=c(0,0,1.5,0))
```


Firms and geo:
```{r}

```
## PCA 
```{r}

```
## Regression
```{r}




```
## Clustering 
```{r}

```

## Supervised Learning data

# Import dataset
```{r Load additional datasets}
# loading data
require(readr)
educ        <- read.csv("./data/level_education.csv", sep =";")
immig       <- read.csv("./data/Immig.csv", sep =";")
categ_socio <- read.csv("./data/Categorie_socioprofessionnelle.csv", sep =";")
status_work <- read.csv("./data/Emplois_lieu_travail.csv", sep =";")
ineq        <- read.csv("./data/Comparateur_territoires.csv", sep =";")
```

# Pre-processing
```{r Check names}
# names(educ)
# names(immig)
# names(categ_socio)
# names(status_work)
# names(ineq)
```

To better understand the data we assign meaningful names and drop some variables which are not needed (at the moment):
```{r Educ-rename variables}
names(educ)[3:11] <-
  c("M_NoDip_Age15",
    "F_NoDip_Age15",
    "M_Sec_Age15",
    "F_Sec_Age15",
    "M_Hi_Age15",
    "F_Hi_Age15",
    "M_univ_Age15",
    "F_univ_Age15")
```

```{r Ineq-Drop unnecessary columns and rename them }
ineq <- subset(ineq, select = -c(P09_POP, NAISD16, DECESD16, P14_RP_PROP, P09_EMPLT,ETTOT15, ETAZ15, ETBE15, ETFZ15, ETGU15, ETGZ15, ETOQ15, ETTEF115, ETTEFP1015))

names(ineq)[5:ncol(ineq)] <-
  c("pop_2014",
    "Superficie",
    "birth09_14",
    "death09_14",
    "households14",
    "housing14",
    "princ_resid14",
    "sec_resid14",
    "vac_resid14",
    "tax_house14",
    "shared_tax_house14",
    "median_living14",
    "lev_ineq14",
    "empl",
    "emp_sal",
    "pop15_64",
    "unemp15_64",
    "act15_64")
```

```{r Categ_socio-rename variables }
names(categ_socio)[3:ncol(categ_socio)] <-
  c("M_immi_agri",
    "F_immi_agri",
    "M_NoImmi_agri",
    "F_NoImmi_agri",
    "M_immi_comm",
    "F_immi_comm",
    "M_NoImmi_comm",
    "F_NoImmi_comm",
    "M_immi_exec",
    "F_immi_exec",
    "M_NoImmi_exec",
    "F_NoImmi_exec",
    "M_immi_midman",
    "F_immi_midman",
    "M_NoImmi_midman",
    "F_NoImmi_midman",
    "M_immi_emp",
    "F_immi_emp",
    "M_NoImmi_emp",
    "F_NoImmi_emp",
    "M_immi_worker",
    "F_immi_worker",
    "M_NoImmi_worker",
    "F_NoImmi_worker",
    "M_immi_retired",
    "F_immi_retired",
    "M_NoImmi_retired",
    "F_NoImmi_retired",
    "M_immi_noAct",
    "F_immi_noAct",
    "M_NoImmi_noAct",
    "F_NoImmi_noAct")

#total number immigrants (male/female) per CODGEO
tot_immig<- ddply(categ_socio, .(CODGEO), function(categ_socio) {
  data.frame(total_immig = sum(categ_socio$M_immi_agri, categ_socio$F_immi_agri, categ_socio$M_immi_comm, categ_socio$F_immi_comm, categ_socio$M_immi_exec, categ_socio$F_immi_exec, categ_socio$M_immi_midman, categ_socio$F_immi_midman, categ_socio$M_immi_noAct, categ_socio$F_immi_noAct, categ_socio$M_immi_retired, categ_socio$F_immi_retired, categ_socio$M_immi_emp, categ_socio$F_immi_emp, categ_socio$M_immi_worker, categ_socio$F_immi_worker),
             male_immig = sum(categ_socio$M_immi_agri, categ_socio$M_immi_comm,categ_socio$M_immi_emp, categ_socio$M_immi_emp, categ_socio$M_immi_exec, categ_socio$M_immi_midman, categ_socio$M_immi_noAct, categ_socio$M_immi_retired, categ_socio$M_immi_worker),
             female_immig = sum(categ_socio$F_immi_agri,categ_socio$F_immi_comm, categ_socio$F_immi_emp, categ_socio$F_immi_emp, categ_socio$F_immi_exec, categ_socio$F_immi_midman, categ_socio$F_immi_noAct, categ_socio$F_immi_retired, categ_socio$F_immi_worker)
  )})

```

